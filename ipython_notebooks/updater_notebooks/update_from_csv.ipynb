{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify cell below before running all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reaction_family = 'H_Abstraction'\n",
    "\n",
    "csv_path = 'distance_data.csv' #does not get appended to general path\n",
    "\n",
    "import os\n",
    "general_path = os.path.join(os.path.expandvars('$RMGpy'),\n",
    "                            '..', \n",
    "                            'AutoTST', \n",
    "                            'database', \n",
    "                            reaction_family, \n",
    "                            'TS_training')\n",
    "\n",
    "new_dict_path = os.path.join(general_path, 'updated_dictionary.txt')\n",
    "new_reactions_path = os.path.join(general_path, 'updated_reactions.py')\n",
    "\n",
    "method = 'm062x/6-311+G(2df,2p)'\n",
    "shortDesc = 'M06-2X/6-311+G(2df,2p) calculation via group additive TS generator.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pylab\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "matplotlib.rc('mathtext', fontset='stixsans', default='regular')\n",
    "import re\n",
    "import rmgpy\n",
    "from rmgpy.quantity import constants\n",
    "from rmgpy.kinetics import Arrhenius, ArrheniusEP, KineticsData\n",
    "from rmgpy.data.base import getAllCombinations\n",
    "from autotst.database import *\n",
    "from rmgpy.species import Species\n",
    "from rmgpy.data.rmg import RMGDatabase\n",
    "import logging\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import IPython\n",
    "from IPython.display import display, Markdown\n",
    "def mprint(s): display(Markdown(s))\n",
    "import cPickle as pickle\n",
    "# attempt at making the cells wider:\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv(path):\n",
    "    add_df = pd.DataFrame.from_csv(path)\n",
    "\n",
    "    results = defaultdict(OrderedDict)\n",
    "    for i, entry in enumerate(add_df.index):\n",
    "        r = OrderedDict()\n",
    "\n",
    "        label = add_df.T[entry].name\n",
    "        reactants, products = label.split('_')\n",
    "        r1, r2 = reactants.split('+')\n",
    "        p1, p2 = products.split('+')\n",
    "\n",
    "        #label = label.replace('+', ' + ')\n",
    "        #label = label.replace('_', ' <=> ')\n",
    "\n",
    "        #r['label'] = label\n",
    "\n",
    "        r['species'] = [r1, r2, p1, p2]\n",
    "        #print r['species']\n",
    "        assert len(r['species']) == 4\n",
    "        r['d12'] = add_df.T[entry]['d12']\n",
    "        r['d13'] = add_df.T[entry]['d13']\n",
    "        r['d23'] = add_df.T[entry]['d23']\n",
    "        assert r['d12'] > 0\n",
    "        assert r['d13'] > 0\n",
    "        assert r['d23'] > 0\n",
    "        \n",
    "        results[i] = r\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_need_to_add(csv_df, known_species):\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    for i, row in csv_df.T.iterrows():\n",
    "\n",
    "        r1, r2, p1, p2 = row['species']\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        reaction = Reaction(reactants = [mr1, mr2],\n",
    "                            products = [mp1, mp2],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\n",
    "        \n",
    "        relavent_species = [mr1, mr2, mp1, mp2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            if rel_species not in found_species.keys():\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "            \"\"\"try:\n",
    "                a = found_species[rel_species]\n",
    "            except:\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "                #relavent_labels[rel_species] = '****'\n",
    "                #logging.warning('{} is missing from species dictionary'.format(rel_species))\n",
    "\n",
    "            \"\"\"\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    return need_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autotst.updater_methods as UPmethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_reactions(path, csv_df, known_species, Method = '', ShortDesc = ''):\n",
    "    # Loading reactions database\n",
    "    from autotst.database import TransitionStateDepository, DistanceData\n",
    "    r_db = TransitionStateDepository()\n",
    "    local_context = {'DistanceData': DistanceData}\n",
    "    r_db.load(path, local_context=local_context)\n",
    "    \n",
    "    # Old r_db only has reactions already in reactions.py\n",
    "    old_r_db = TransitionStateDepository()\n",
    "    old_r_db.load(path, local_context=local_context)\n",
    "    \n",
    "    # New r_db will contain new reactions from the csv_df\n",
    "    new_r_db = TransitionStateDepository()\n",
    "\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    Index = 0\n",
    "    for entry in r_db.entries.values():\n",
    "        if Index < entry.index:\n",
    "            Index = entry.index\n",
    "    Index = Index + 1\n",
    "\n",
    "    for i, row in csv_df.T.iterrows():\n",
    "        #every reaction needs: distances, method, shortDesc, label, and reaction object\n",
    "\n",
    "        r1, r2, p1, p2 = row['species']\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        reaction = Reaction(reactants = [Species(molecule=[mr1]), Species(molecule=[mr2])],\n",
    "                            products = [Species(molecule=[mp1]), Species(molecule=[mp2])],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\n",
    "\n",
    "\n",
    "        Distances = {'d12':row['d12'], 'd13':row['d13'], 'd23':row['d23']}\n",
    "        distance_data = DistanceData(distances = Distances, method = Method)\n",
    "\n",
    "        relavent_species = [mr1, mr2, mp1, mp2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            \n",
    "            if rel_species not in found_species.keys():\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "\n",
    "        lr1 = relavent_labels[mr1]\n",
    "        lr2 = relavent_labels[mr2]\n",
    "        lp1 = relavent_labels[mp1]\n",
    "        lp2 = relavent_labels[mp2]\n",
    "\n",
    "        Label = '{} + {} <=> {} + {}'.format(lr1, lr2, lp1, lp2)\n",
    "        #print Label\n",
    "\n",
    "        # adding new entries to r_db, r_db will contain old and new reactions\n",
    "        r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = ShortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "        r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = reaction\n",
    "\n",
    "        # Adding new reactions to the new r_db as well\n",
    "        new_r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = ShortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "        new_r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = reaction\n",
    "\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    assert len(need_to_add) == 0, 'Species missing from dictionary'\n",
    "    assert len(r_db.entries) > len(old_r_db.entries) and len(r_db.entries) > len(new_r_db.entries)\n",
    "    assert len(r_db.entries) == len(old_r_db.entries) + len(new_r_db.entries) \n",
    "    \n",
    "    return r_db, old_r_db, new_r_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_databases_from_csv(gen_path, csv_path, new_dict_path, new_reactions_path, method_str='', shortDesc_str=''):\n",
    "    \"\"\"\n",
    "    csv_path = 'distance_data.csv'\n",
    "    dict_path = 'database/H_Abstraction/TS_training/dictionary.txt'\n",
    "    old_style_dict_path = 'database/H_Abstraction/TS_training/old_dictionary.txt'\n",
    "    new_dict_path = 'updated_dictionary.txt'\n",
    "    \n",
    "    method_str = 'm062x/6-311+G(2df,2p)'\n",
    "    shortDesc_str = 'M06-2X/6-311+G(2df,2p) calculation via group additive TS generator.'\n",
    "    old_reactions_path = 'database/H_Abstraction/TS_training/reactions.py'\n",
    "    new_reactions_path = 'updated_reactions.py'\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_path = os.path.join(general_path, 'dictionary.txt')\n",
    "    old_reactions_path = os.path.join(general_path, 'reactions.py')\n",
    "    \n",
    "    csv_df = get_csv(csv_path)\n",
    "    print 'New Reactions: ', csv_df.shape[1]\n",
    "\n",
    "    known_species = rmgpy.data.base.Database().getSpecies(dict_path)\n",
    "    need_to_add = get_need_to_add(csv_df=csv_df, known_species=known_species)\n",
    "\n",
    "    if len(need_to_add) > 0:\n",
    "        print 'New Species: ', len(need_to_add)\n",
    "        old_entries = UPmethods.rote_load_dict(dict_path)\n",
    "        all_dict_entries = UPmethods.update_dictionary_entries(old_entries, need_to_add)\n",
    "        \n",
    "        if UPmethods.check_dictionary_entries(all_dict_entries):\n",
    "            UPmethods.rote_save_dictionary(new_dict_path, all_dict_entries)\n",
    "    \n",
    "        known_species = rmgpy.data.base.Database().getSpecies(new_dict_path)\n",
    "    else:\n",
    "        print \"No new species found.\"\n",
    "\n",
    "    r_db, old_db, new_db = update_reactions(old_reactions_path,\n",
    "                                            csv_df,\n",
    "                                            known_species,\n",
    "                                            Method = method_str,\n",
    "                                            ShortDesc = shortDesc_str)\n",
    "    print\n",
    "    print 'Old Reactions:', len(old_db.entries)\n",
    "    print 'Reactions added:', len(new_db.entries)\n",
    "    print 'Final Reactions:', len(r_db.entries)\n",
    "    \n",
    "    #TODO add check for duplicates method\n",
    "    #if check_reactions():\n",
    "    if True:\n",
    "        logging.warning('No duplicate check for reactions database')\n",
    "        r_db.save(new_reactions_path)\n",
    "        logging.info('Reactions and their species saved to...\\n{}\\n...and...\\n{}\\n...respectively'.format(new_reactions_path, new_dict_path))\n",
    "    print\n",
    "    print 'done'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Reactions:  920\n",
      "New Species:  985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No duplicate check for reactions database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Old Reactions: 2490\n",
      "Reactions added: 920\n",
      "Final Reactions: 3410\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "update_databases_from_csv(general_path,\n",
    "                          csv_path,\n",
    "                          new_dict_path,\n",
    "                          new_reactions_path,\n",
    "                          method_str=method,\n",
    "                          shortDesc_str=shortDesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
