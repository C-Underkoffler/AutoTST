{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to sort out how to handle duplicate reactions being add to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the csv import to quickly grab a test reactions database that I think will have duplicates in it. Run All the way down to the cells past update_database_from_csv() to get to actual duplicate stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reaction_family = 'H_Abstraction'\n",
    "\n",
    "csv_path = 'distance_data.csv' #does not get appended to general path\n",
    "\n",
    "import os\n",
    "general_path = os.path.join(os.path.expandvars('$RMGpy'),\n",
    "                            '..', \n",
    "                            'AutoTST', \n",
    "                            'database', \n",
    "                            reaction_family, \n",
    "                            'TS_training')\n",
    "\n",
    "new_dict_path = os.path.join(general_path, 'updated_dictionary.txt')\n",
    "new_reactions_path = os.path.join(general_path, 'updated_reactions.py')\n",
    "\n",
    "method = 'm062x/6-311+G(2df,2p)'\n",
    "shortDesc = 'M06-2X/6-311+G(2df,2p) calculation via group additive TS generator.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pylab\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "matplotlib.rc('mathtext', fontset='stixsans', default='regular')\n",
    "import re\n",
    "import rmgpy\n",
    "from rmgpy.quantity import constants\n",
    "from rmgpy.kinetics import Arrhenius, ArrheniusEP, KineticsData\n",
    "from rmgpy.data.base import getAllCombinations\n",
    "from autotst.database import *\n",
    "from rmgpy.species import Species\n",
    "from rmgpy.data.rmg import RMGDatabase\n",
    "import logging\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import IPython\n",
    "from IPython.display import display, Markdown\n",
    "def mprint(s): display(Markdown(s))\n",
    "import cPickle as pickle\n",
    "# attempt at making the cells wider:\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv(path):\n",
    "    add_df = pd.DataFrame.from_csv(path)\n",
    "\n",
    "    results = defaultdict(OrderedDict)\n",
    "    for i, entry in enumerate(add_df.index):\n",
    "        r = OrderedDict()\n",
    "\n",
    "        label = add_df.T[entry].name\n",
    "        reactants, products = label.split('_')\n",
    "        r1, r2 = reactants.split('+')\n",
    "        p1, p2 = products.split('+')\n",
    "\n",
    "        #label = label.replace('+', ' + ')\n",
    "        #label = label.replace('_', ' <=> ')\n",
    "\n",
    "        #r['label'] = label\n",
    "\n",
    "        r['species'] = [r1, r2, p1, p2]\n",
    "        #print r['species']\n",
    "        assert len(r['species']) == 4\n",
    "        r['d12'] = add_df.T[entry]['d12']\n",
    "        r['d13'] = add_df.T[entry]['d13']\n",
    "        r['d23'] = add_df.T[entry]['d23']\n",
    "        assert r['d12'] > 0\n",
    "        assert r['d13'] > 0\n",
    "        assert r['d23'] > 0\n",
    "        \n",
    "        results[i] = r\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_need_to_add(csv_df, known_species):\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    for i, row in csv_df.T.iterrows():\n",
    "\n",
    "        r1, r2, p1, p2 = row['species']\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        reaction = Reaction(reactants = [mr1, mr2],\n",
    "                            products = [mp1, mp2],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\n",
    "        \n",
    "        relavent_species = [mr1, mr2, mp1, mp2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            if rel_species not in found_species.keys():\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "            \"\"\"try:\n",
    "                a = found_species[rel_species]\n",
    "            except:\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "                #relavent_labels[rel_species] = '****'\n",
    "                #logging.warning('{} is missing from species dictionary'.format(rel_species))\n",
    "\n",
    "            \"\"\"\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    return need_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autotst.updater_methods as UPmethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_reactions(path, csv_df, known_species, Method = '', ShortDesc = ''):\n",
    "    # Loading reactions database\n",
    "    from autotst.database import TransitionStateDepository, DistanceData\n",
    "    r_db = TransitionStateDepository()\n",
    "    local_context = {'DistanceData': DistanceData}\n",
    "    r_db.load(path, local_context=local_context)\n",
    "    \n",
    "    # Old r_db only has reactions already in reactions.py\n",
    "    old_r_db = TransitionStateDepository()\n",
    "    old_r_db.load(path, local_context=local_context)\n",
    "    \n",
    "    # New r_db will contain new reactions from the csv_df\n",
    "    new_r_db = TransitionStateDepository()\n",
    "\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    Index = 0\n",
    "    for entry in r_db.entries.values():\n",
    "        if Index < entry.index:\n",
    "            Index = entry.index\n",
    "    Index = Index + 1\n",
    "\n",
    "    for i, row in csv_df.T.iterrows():\n",
    "        #every reaction needs: distances, method, shortDesc, label, and reaction object\n",
    "\n",
    "        r1, r2, p1, p2 = row['species']\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        reaction = Reaction(reactants = [Species(molecule=[mr1]), Species(molecule=[mr2])],\n",
    "                            products = [Species(molecule=[mp1]), Species(molecule=[mp2])],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\n",
    "\n",
    "\n",
    "        Distances = {'d12':row['d12'], 'd13':row['d13'], 'd23':row['d23']}\n",
    "        distance_data = DistanceData(distances = Distances, method = Method)\n",
    "\n",
    "        relavent_species = [mr1, mr2, mp1, mp2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            \n",
    "            if rel_species not in found_species.keys():\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "\n",
    "        lr1 = relavent_labels[mr1]\n",
    "        lr2 = relavent_labels[mr2]\n",
    "        lp1 = relavent_labels[mp1]\n",
    "        lp2 = relavent_labels[mp2]\n",
    "\n",
    "        Label = '{} + {} <=> {} + {}'.format(lr1, lr2, lp1, lp2)\n",
    "        #print Label\n",
    "\n",
    "        # adding new entries to r_db, r_db will contain old and new reactions\n",
    "        r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = ShortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "        r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = reaction\n",
    "        \n",
    "        # Adding new reactions to the new r_db as well\n",
    "        new_r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = ShortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "        new_r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = reaction\n",
    "\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    assert len(need_to_add) == 0, 'Species missing from dictionary'\n",
    "    assert len(r_db.entries) > len(old_r_db.entries) and len(r_db.entries) > len(new_r_db.entries)\n",
    "    assert len(r_db.entries) == len(old_r_db.entries) + len(new_r_db.entries) \n",
    "    \n",
    "    return r_db, old_r_db, new_r_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_databases_from_csv(gen_path, csv_path, new_dict_path, new_reactions_path, method_str='', shortDesc_str=''):\n",
    "    \"\"\"\n",
    "    csv_path = 'distance_data.csv'\n",
    "    dict_path = 'database/H_Abstraction/TS_training/dictionary.txt'\n",
    "    old_style_dict_path = 'database/H_Abstraction/TS_training/old_dictionary.txt'\n",
    "    new_dict_path = 'updated_dictionary.txt'\n",
    "    \n",
    "    method_str = 'm062x/6-311+G(2df,2p)'\n",
    "    shortDesc_str = 'M06-2X/6-311+G(2df,2p) calculation via group additive TS generator.'\n",
    "    old_reactions_path = 'database/H_Abstraction/TS_training/reactions.py'\n",
    "    new_reactions_path = 'updated_reactions.py'\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_path = os.path.join(general_path, 'dictionary.txt')\n",
    "    old_reactions_path = os.path.join(general_path, 'reactions.py')\n",
    "    \n",
    "    csv_df = get_csv(csv_path)\n",
    "    print 'New Reactions: ', csv_df.shape[1]\n",
    "\n",
    "    known_species = rmgpy.data.base.Database().getSpecies(dict_path)\n",
    "    need_to_add = get_need_to_add(csv_df=csv_df, known_species=known_species)\n",
    "\n",
    "    if len(need_to_add) > 0:\n",
    "        print 'New Species: ', len(need_to_add)\n",
    "        old_entries = UPmethods.rote_load_dict(dict_path)\n",
    "        all_dict_entries = UPmethods.update_dictionary_entries(old_entries, need_to_add)\n",
    "        \n",
    "        if UPmethods.check_dictionary_entries(all_dict_entries):\n",
    "            UPmethods.rote_save_dictionary(new_dict_path, all_dict_entries)\n",
    "    \n",
    "        known_species = rmgpy.data.base.Database().getSpecies(new_dict_path)\n",
    "    else:\n",
    "        print \"No new species found.\"\n",
    "\n",
    "    r_db, old_db, new_db = update_reactions(old_reactions_path,\n",
    "                                            csv_df,\n",
    "                                            known_species,\n",
    "                                            Method = method_str,\n",
    "                                            ShortDesc = shortDesc_str)\n",
    "    print\n",
    "    print 'Old Reactions:', len(old_db.entries)\n",
    "    print 'Reactions added:', len(new_db.entries)\n",
    "    print 'Final Reactions:', len(r_db.entries)\n",
    "    \n",
    "    #TODO add check for duplicates method\n",
    "    #if check_reactions():\n",
    "    if True:\n",
    "        logging.warning('No duplicate check for reactions database')\n",
    "        r_db.save(new_reactions_path)\n",
    "        logging.info('Reactions and their species saved to...\\n{}\\n...and...\\n{}\\n...respectively'.format(new_reactions_path, new_dict_path))\n",
    "    print\n",
    "    print 'done'\n",
    "    return r_db, new_db, old_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Reactions:  920\n",
      "New Species:  985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No duplicate check for reactions database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Old Reactions: 2490\n",
      "Reactions added: 920\n",
      "Final Reactions: 3410\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "comp, new, old = update_databases_from_csv(general_path,\n",
    "                          csv_path,\n",
    "                          new_dict_path,\n",
    "                          new_reactions_path,\n",
    "                          method_str=method,\n",
    "                          shortDesc_str=shortDesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_duplicates(r_database, power):\n",
    "    checked_entries = []\n",
    "    \n",
    "    # Entries that do not have a duplicate in the same direction\n",
    "    clean_entries = {}\n",
    "    \n",
    "    # For reactions that are isomorphic, but TS geometry seems to be mislablled (d12 and d23 swapped for example)\n",
    "    swapped_dists = []\n",
    "    \n",
    "    # For reactions that are isomorphic, and TS geometry is very similar per the given tolerance\n",
    "    similar_dists = {}\n",
    "    \n",
    "    # For isomporphic reactions that have distances that vary greater than the given tolerance\n",
    "    big_diff = []\n",
    "    \n",
    "    # Keeping track of forward and reverse reaction pairs\n",
    "    pairs = {}\n",
    "    \n",
    "    # Tolerance used to diffrentiate between acceptably similar geometries and those that are conflicting  \n",
    "    tolerance = 10**-power\n",
    "\n",
    "    logging.info('Tolerance of {} for duplicate reaction check'.format(tolerance))\n",
    "\n",
    "    for entry in r_database.entries.values():\n",
    "        reaction = entry.item\n",
    "        distances = entry.data.distances\n",
    "        clean = True\n",
    "\n",
    "        for c_entry in checked_entries:\n",
    "            c_reaction = c_entry.item\n",
    "            c_distances = c_entry.data.distances\n",
    "\n",
    "            if reaction.isIsomorphic(c_reaction, eitherDirection = False):\n",
    "                #Check if reaction is isomorphic and in same direction\n",
    "                \n",
    "                clean = False\n",
    "                if c_entry in clean_entries.keys():\n",
    "                    # Backtracking to make sure all entries in the following are clean\n",
    "                    del clean_entries[c_entry]\n",
    "                \n",
    "                if c_entry in pairs.keys():\n",
    "                    # Backtracking to make sure all entries in the following are clean\n",
    "                    del pairs[c_entry]\n",
    "\n",
    "                ds = [round(distances[key], power) for key in distances]\n",
    "                c_ds = [round(c_distances[key], power) for key in c_distances]\n",
    "\n",
    "                if set(sorted(ds)) == set(sorted(c_ds)):\n",
    "                    #Similar values, but maybe not the same keys (swapped)\n",
    "\n",
    "                    avg_d = {}\n",
    "                    for key in distances:\n",
    "                        d = distances[key]\n",
    "                        c_d = c_distances[key]\n",
    "\n",
    "                        if abs(d-c_d) < tolerance:\n",
    "                            #Only take average if distances are very similar\n",
    "                            avg_d[key] = (d+c_d)/2\n",
    "\n",
    "                    if len(avg_d) != len(distances):\n",
    "                        # Keys don't align: Swapped\n",
    "                        swapped_dists.append([entry, c_entry])\n",
    "                    elif len(avg_d) == len(distances):\n",
    "                        # Keys most likely align and so the distances are very similar\n",
    "                        similar_dists[entry] = c_entry, avg_d\n",
    "                        \n",
    "                else:\n",
    "                    #Not at all similar based off of tolerance (power)\n",
    "                    \"\"\"print reaction\n",
    "                    print c_reaction\n",
    "                    print distances\n",
    "                    print c_distances\n",
    "                    print\n",
    "                    print avg_d\n",
    "                    assert False\"\"\"\n",
    "                    big_diff.append([entry, c_entry])\n",
    "            elif reaction.isIsomorphic(c_reaction, eitherDirection = True):\n",
    "                #Check there is forward and reverse of all clean reactions\n",
    "                # entry gets added to pairs if it has a pair, later removed if it is not clean\n",
    "                pairs[entry] = c_entry\n",
    "                \n",
    "        \n",
    "        if clean:\n",
    "            clean_entries[entry] = 1\n",
    "        else:\n",
    "            if entry in pairs.keys():\n",
    "                del pairs[entry]\n",
    "           \n",
    "\n",
    "        checked_entries.append(entry)\n",
    "        \n",
    "    # Should be unique already but just to be sure\n",
    "    clean_entries = list(set(clean_entries))\n",
    "    \n",
    "    logging.info('Total Entries: {}'.format(len(checked_entries)))\n",
    "    logging.info(\"Swapped Distances: {}\".format(len(swapped_dists)))\n",
    "    logging.info(\"Not swapped and off: {}\".format(len(big_diff)))\n",
    "    logging.info(\"Both directions: {}\".format(len(pairs)))\n",
    "    logging.info(\"Clean Entries: {}\".format(len(clean_entries)))\n",
    "    \n",
    "    print 'Total Entries: {}'.format(len(checked_entries))\n",
    "    print \"Swapped Distances: {}\".format(len(swapped_dists))\n",
    "    print \"Not swapped and off: {}\".format(len(big_diff))\n",
    "    print \"Both directions: {}\".format(len(pairs))\n",
    "    print \"Clean Entries: {}\".format(len(clean_entries))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return clean_entries, swapped_dists, big_diff, similar_dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entries: 3410\n",
      "Swapped Distances: 18\n",
      "Not swapped and off: 48\n",
      "Both directions: 1330\n",
      "Clean Entries: 3242\n"
     ]
    }
   ],
   "source": [
    "# second arg just to set tolerance to 10**-power\n",
    "comp_clean, swapped, diffs, similar  = find_duplicates(comp, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entries: 920\n",
      "Swapped Distances: 1\n",
      "Not swapped and off: 0\n",
      "Both directions: 116\n",
      "Clean Entries: 918\n"
     ]
    }
   ],
   "source": [
    "clean, swapped, diffs, similar = find_duplicates(new, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, swapped, diffs, similar = UPmethods.find_duplicate_reactions(new, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entries: 2490\n",
      "Swapped Distances: 0\n",
      "Not swapped and off: 0\n",
      "Both directions: 1245\n",
      "Clean Entries: 2490\n"
     ]
    }
   ],
   "source": [
    "clean, swapped, diffs, similar = find_duplicates(old, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swapped and conflicting distances needs further verification as which one is correct\n",
    "\n",
    "### Two options: only keep non conflicting and swaps, or give preference to old reactions, leave out conflicts from new reactions  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TS_depository_from_entries(entries):\n",
    "    assert isinstance(entries, list)\n",
    "    \n",
    "    from autotst.database import TransitionStateDepository\n",
    "    depository = TransitionStateDepository()\n",
    "    \n",
    "    for index, entry in enumerate(entries):\n",
    "        clean_db.entries['{0:d}:{1}'.format(index, entry.label)] = entry\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autotst.database import TransitionStateDepository\n",
    "clean_db = TransitionStateDepository()\n",
    "\n",
    "for index, entry in enumerate(comp_clean):\n",
    "    clean_db.entries['{0:d}:{1}'.format(index, entry.label)] = entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All entries without conflicts now in clean_db, could be used to auto save all clean entries then manually select thorugh conflicting entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
