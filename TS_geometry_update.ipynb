{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pylab\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "matplotlib.rc('mathtext', fontset='stixsans', default='regular')\n",
    "import re\n",
    "import rmgpy\n",
    "from rmgpy.quantity import constants\n",
    "from rmgpy.kinetics import Arrhenius, ArrheniusEP, KineticsData\n",
    "from rmgpy.data.base import getAllCombinations\n",
    "from autotst.database import *\n",
    "from rmgpy.species import Species\n",
    "from rmgpy.data.rmg import RMGDatabase\n",
    "import logging\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import IPython\n",
    "from IPython.display import display, Markdown\n",
    "def mprint(s): display(Markdown(s))\n",
    "import cPickle as pickle\n",
    "# attempt at making the cells wider:\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv(path):\n",
    "    add_df = pd.DataFrame.from_csv(path)\n",
    "\n",
    "    results = defaultdict(OrderedDict)\n",
    "    for i, entry in enumerate(add_df.index):\n",
    "        r = OrderedDict()\n",
    "\n",
    "        label = add_df.T[entry].name\n",
    "        reactants, products = label.split('_')\n",
    "        r1, r2 = reactants.split('+')\n",
    "        p1, p2 = products.split('+')\n",
    "\n",
    "        #label = label.replace('+', ' + ')\n",
    "        #label = label.replace('_', ' <=> ')\n",
    "\n",
    "        #r['label'] = label\n",
    "\n",
    "        r['species'] = [r1, r2, p1, p2]\n",
    "        #print r['species']\n",
    "        assert len(r['species']) == 4\n",
    "        r['d12'] = add_df.T[entry]['d12']\n",
    "        r['d13'] = add_df.T[entry]['d13']\n",
    "        r['d23'] = add_df.T[entry]['d23']\n",
    "        assert r['d12'] > 0\n",
    "        assert r['d13'] > 0\n",
    "        assert r['d23'] > 0\n",
    "        \n",
    "        results[i] = r\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_need_to_add(csv_df, known_species):\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    for i, row in csv_df.T.iterrows():\n",
    "\n",
    "        r1, r2, p1, p2 = row['species']\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        reaction = Reaction(reactants = [mr1, mr2],\n",
    "                            products = [mp1, mp2],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\n",
    "        \n",
    "        relavent_species = [mr1, mr2, mp1, mp2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            if rel_species not in found_species.keys():\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "            \"\"\"try:\n",
    "                a = found_species[rel_species]\n",
    "            except:\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "                #relavent_labels[rel_species] = '****'\n",
    "                #logging.warning('{} is missing from species dictionary'.format(rel_species))\n",
    "\n",
    "            \"\"\"\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    return need_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unknown_species(reactions, known_species):\n",
    "    \"\"\"\n",
    "    Expects list of auto-TST reactions and known species from a species dictionary\n",
    "    \n",
    "    Returns unique list of SMILES of species not in the dictionary\n",
    "    \"\"\"\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    for i, reaction in enumerate(reactions):\n",
    "        rmg_reaction = reaction.rmg_reaction\n",
    "        r1, r2 = rmg_reaction.reactants\n",
    "        p1, p2 = rmg_reaction.products\n",
    "        \n",
    "        relavent_species = [r1, r2, p1, p2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            if rel_species not in found_species.keys():\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    return need_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_dictionary_entries(old_entries, need_to_add):\n",
    "    list(set(need_to_add))\n",
    "    for j, species in enumerate(need_to_add):\n",
    "        \n",
    "        molecule = Molecule(SMILES = species)\n",
    "        adjlist = molecule.toAdjacencyList()\n",
    "        \n",
    "        multiplicity = None\n",
    "        multiplicity =  adjlist[adjlist.find(\"multiplicity \")+13:adjlist.find(\"multiplicity \")+14]\n",
    "        if multiplicity is not None:\n",
    "            adjlist = re.sub(r'multiplicity .*', 'multiplicity [{}]'.format(multiplicity), adjlist)\n",
    "\n",
    "        group = rmgpy.molecule.group.Group()\n",
    "        group.fromAdjacencyList(adjlist)\n",
    "\n",
    "        atom_counts = {}\n",
    "        rel_label = ''\n",
    "        for atom in ['C', 'H', 'O']:\n",
    "            count = species.count(atom)\n",
    "            if count > 0:\n",
    "                rel_label = rel_label + atom + str(count)\n",
    "                \n",
    "        assert rel_label != ''\n",
    "        \n",
    "        \"\"\"\n",
    "        3 Scenerios:\n",
    "        No old -> no need for ID number: max_ID = -1\n",
    "        Only one old -> needs to have ID of 1: max_ID = 0\n",
    "        Multiple old -> needs to have a unique ID: max_ID > 0\n",
    "        \"\"\"\n",
    "        \n",
    "        new_ID = None\n",
    "        max_ID = -1\n",
    "        duplicate = False\n",
    "        for old_label in old_entries:\n",
    "            old_entry = old_entries[old_label]\n",
    "            \n",
    "            if group.isIsomorphic(old_entry.item):\n",
    "                duplicate = True\n",
    "                print '{} found to be duplicate'.format(old_entry)\n",
    "                continue\n",
    "            \n",
    "            if rel_label not in old_label:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            if rel_label == old_label and max_ID == -1:\n",
    "                # Atleast one with same label\n",
    "                max_ID = 0\n",
    "                \n",
    "            if old_label.find('-') > 0:\n",
    "                old_label, ID_str = old_label.split('-')\n",
    "                ID = int(ID_str)\n",
    "                \n",
    "                if old_label == rel_label and ID > max_ID:\n",
    "                    # Multiple exisitng labels\n",
    "                    max_ID = ID\n",
    "\n",
    "        if max_ID > -1:\n",
    "            #All with old labels\n",
    "            new_ID = max_ID + 1\n",
    "            rel_label = rel_label + '-' + str(new_ID)\n",
    "\n",
    "        if not duplicate:\n",
    "            entry = Entry()\n",
    "            entry.label = rel_label\n",
    "            entry.item = group\n",
    "            assert rel_label not in old_entries.keys()\n",
    "            old_entries[rel_label] = entry\n",
    "        \n",
    "        \n",
    "    entry_labels = [old_entries[key].label for key in old_entries]\n",
    "    \n",
    "    assert len(entry_labels) == len(list(set(entry_labels))), 'Non-unique labels in dictionary'\n",
    "    \n",
    "    \n",
    "    return old_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-8-58bd23532fa1>, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-58bd23532fa1>\"\u001b[0;36m, line \u001b[0;32m38\u001b[0m\n\u001b[0;31m    3 Scenerios:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"def update_dictionary_entries(loud_path, need_to_add):\n",
    "    \n",
    "    library = rmgpy.data.kinetics.library.KineticsLibrary()\n",
    "    pattern = True\n",
    "    library.loadOldDictionary(load_path, pattern=pattern)\n",
    "\n",
    "    print 'Starting Species:', len(library.entries.values()) \n",
    "\n",
    "    for i, entry in enumerate(library.entries.values()):\n",
    "        entry.index = i\n",
    "        library.entries[entry.index] = entry\n",
    "        del library.entries[entry.label]\n",
    "    \n",
    "    print 'Starting Species:', len(entries)\n",
    "\n",
    "    # Recycling i to help make unique indices moving forward\n",
    "    i = i+2\n",
    "\n",
    "    for j, species in enumerate(need_to_add):\n",
    "        mole = Molecule(SMILES = species)\n",
    "\n",
    "        adjlist = mole.toAdjacencyList()\n",
    "        multiplicity = None\n",
    "        multiplicity =  adjlist[adjlist.find(\"multiplicity \")+13:adjlist.find(\"multiplicity \")+14]\n",
    "        if multiplicity is not None:\n",
    "            adjlist = re.sub(r'multiplicity .*', 'multiplicity [{}]'.format(multiplicity), adjlist)\n",
    "\n",
    "        group = rmgpy.molecule.group.Group()\n",
    "        group.fromAdjacencyList(adjlist)\n",
    "\n",
    "        atom_counts = {}\n",
    "        rel_label = ''\n",
    "        for atom in ['C', 'H', 'O']:\n",
    "            atom_counts[atom] = species.count(atom)\n",
    "            if species.count(atom) > 0:\n",
    "                rel_label = rel_label + atom + str(species.count(atom))\n",
    "        \"\"\"\n",
    "        3 Scenerios:\n",
    "        No existing -> no need for ID number: max_ID = -1\n",
    "        Only one existing -> needs to have ID of 1: max_ID = 0\n",
    "        Multiple existing -> needs to have a unique ID: max_ID > 0\n",
    "        \"\"\"\n",
    "        new_ID = None\n",
    "        max_ID = -1\n",
    "        for entry in library.entries.values():\n",
    "            existing_label = entry.label\n",
    "\n",
    "            if rel_label not in existing_label:\n",
    "                continue\n",
    "\n",
    "            if rel_label == existing_label:\n",
    "                # Atleast one, but not necessarily more existing with same label\n",
    "                max_ID = 0\n",
    "\n",
    "            #print rel_label, ' : ', existing_label\n",
    "            if existing_label.find('-') > 0:\n",
    "                ID_str = existing_label[existing_label.find('-')+1:]\n",
    "                ID = int(ID_str)\n",
    "                existing_label = existing_label[:existing_label.find('-')]\n",
    "\n",
    "                if existing_label == rel_label and ID > max_ID:\n",
    "                    # Multiple exisitng labels\n",
    "                    max_ID = ID\n",
    "\n",
    "        if max_ID > -1:\n",
    "            #All with existing labels\n",
    "            new_ID = max_ID + 1\n",
    "            rel_label = rel_label + '-' + str(new_ID)\n",
    "\n",
    "        #print '\\t', rel_label, ':', max_ID\n",
    "\n",
    "        library.loadEntry(i+j,\n",
    "                          rel_label,\n",
    "                          None,\n",
    "                          degeneracy=1,\n",
    "                          duplicate=False,\n",
    "                          reversible=True,\n",
    "                          reference=None,\n",
    "                          referenceType='',\n",
    "                          shortDesc='',\n",
    "                          longDesc='',\n",
    "                          has_pdep_route=False,\n",
    "                          )\n",
    "\n",
    "        library.entries[i+j].item = group\n",
    "\n",
    "        \n",
    "    entry_labels = [entry.label for entry in library.entries.values()]\n",
    "    assert len(entry_labels) == len(list(set(entry_labels))), 'Non-unique labels in dictionary'\n",
    "\n",
    "    print 'Final Species:', len(library.entries)\n",
    "    \n",
    "    return library.entries.values()\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_updated_dictionary_entries(load_path, need_to_add):\n",
    "    \n",
    "    library = rmgpy.data.kinetics.library.KineticsLibrary()\n",
    "    pattern = True\n",
    "    library.loadOldDictionary(load_path, pattern=pattern)\n",
    "\n",
    "    print 'Starting Species:', len(library.entries.values()) \n",
    "\n",
    "    for i, entry in enumerate(library.entries.values()):\n",
    "        entry.index = i\n",
    "        library.entries[entry.index] = entry\n",
    "        del library.entries[entry.label]\n",
    "    \n",
    "    # Recycling i to help make unique indices moving forward\n",
    "    i = i+2\n",
    "\n",
    "    for j, species in enumerate(need_to_add):\n",
    "        mole = Molecule(SMILES = species)\n",
    "\n",
    "        adjlist = mole.toAdjacencyList()\n",
    "        multiplicity = None\n",
    "        multiplicity =  adjlist[adjlist.find(\"multiplicity \")+13:adjlist.find(\"multiplicity \")+14]\n",
    "        if multiplicity is not None:\n",
    "            adjlist = re.sub(r'multiplicity .*', 'multiplicity [{}]'.format(multiplicity), adjlist)\n",
    "\n",
    "        group = rmgpy.molecule.group.Group()\n",
    "        group.fromAdjacencyList(adjlist)\n",
    "\n",
    "        atom_counts = {}\n",
    "        rel_label = ''\n",
    "        for atom in ['C', 'H', 'O']:\n",
    "            atom_counts[atom] = species.count(atom)\n",
    "            if species.count(atom) > 0:\n",
    "                rel_label = rel_label + atom + str(species.count(atom))\n",
    "        \"\"\"\n",
    "        3 Scenerios:\n",
    "        No existing -> no need for ID number: max_ID = -1\n",
    "        Only one existing -> needs to have ID of 1: max_ID = 0\n",
    "        Multiple existing -> needs to have a unique ID: max_ID > 0\n",
    "        \"\"\"\n",
    "        new_ID = None\n",
    "        max_ID = -1\n",
    "        for entry in library.entries.values():\n",
    "            existing_label = entry.label\n",
    "\n",
    "            if rel_label not in existing_label:\n",
    "                continue\n",
    "\n",
    "            if rel_label == existing_label:\n",
    "                # Atleast one, but not necessarily more existing with same label\n",
    "                max_ID = 0\n",
    "\n",
    "            #print rel_label, ' : ', existing_label\n",
    "            if existing_label.find('-') > 0:\n",
    "                ID_str = existing_label[existing_label.find('-')+1:]\n",
    "                ID = int(ID_str)\n",
    "                existing_label = existing_label[:existing_label.find('-')]\n",
    "\n",
    "                if existing_label == rel_label and ID > max_ID:\n",
    "                    # Multiple exisitng labels\n",
    "                    max_ID = ID\n",
    "\n",
    "        if max_ID > -1:\n",
    "            #All with existing labels\n",
    "            new_ID = max_ID + 1\n",
    "            rel_label = rel_label + '-' + str(new_ID)\n",
    "\n",
    "        #print '\\t', rel_label, ':', max_ID\n",
    "\n",
    "        library.loadEntry(i+j,\n",
    "                          rel_label,\n",
    "                          None,\n",
    "                          degeneracy=1,\n",
    "                          duplicate=False,\n",
    "                          reversible=True,\n",
    "                          reference=None,\n",
    "                          referenceType='',\n",
    "                          shortDesc='',\n",
    "                          longDesc='',\n",
    "                          has_pdep_route=False,\n",
    "                          )\n",
    "\n",
    "        library.entries[i+j].item = group\n",
    "\n",
    "        \n",
    "    entry_labels = [entry.label for entry in library.entries.values()]\n",
    "    assert len(entry_labels) == len(list(set(entry_labels))), 'Non-unique labels in dictionary'\n",
    "\n",
    "    print 'Final Species:', len(library.entries)\n",
    "    \n",
    "    return library.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_dictionary(dict_entries):\n",
    "    entry_indices = []\n",
    "    entry_adjlists = []\n",
    "    entry_labels = []\n",
    "    for entry in dict_entries:\n",
    "        adjlist = entry.item.toAdjacencyList()\n",
    "        adjlist = re.sub('\\[', '', adjlist)\n",
    "        adjlist = re.sub('\\]', '', adjlist)\n",
    "        assert entry.index not in entry_indices, 'Non-unique indices for dictionary'\n",
    "        assert adjlist not in entry_adjlists, 'Non-unique adjacencies for dictionary'\n",
    "        assert entry.label not in entry_labels, 'Non-unique labels for dictionary'\n",
    "\n",
    "        entry_indices.append(entry.index)\n",
    "        entry_adjlists.append(entry.item.toAdjacencyList())\n",
    "        entry_labels.append(entry.label)\n",
    "    \n",
    "    print 'Checked dictionary'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_dictionary_entries(dict_entries):\n",
    "    entry_indices = []\n",
    "    entry_adjlists = []\n",
    "    entry_labels = []\n",
    "    for entry in dict_entries.values():\n",
    "        adjlist = entry.item.toAdjacencyList()\n",
    "\n",
    "        assert adjlist not in entry_adjlists, 'Non-unique adjacencies for dictionary'\n",
    "        assert entry.label not in entry_labels, 'Non-unique labels for dictionary'\n",
    "\n",
    "        entry_indices.append(entry.index)\n",
    "        entry_adjlists.append(entry.item.toAdjacencyList())\n",
    "        entry_labels.append(entry.label)\n",
    "    \n",
    "    print 'Checked dictionary'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_dictionary(dict_entries):\n",
    "    entry_indices = []\n",
    "    entry_adjlists = []\n",
    "    entry_labels = []\n",
    "    for entry in dict_entries:\n",
    "        adjlist = entry.item.toAdjacencyList()\n",
    "\n",
    "        assert adjlist not in entry_adjlists, 'Non-unique adjacencies for dictionary'\n",
    "        assert entry.label not in entry_labels, 'Non-unique labels for dictionary'\n",
    "\n",
    "        entry_indices.append(entry.index)\n",
    "        entry_adjlists.append(entry.item.toAdjacencyList())\n",
    "        entry_labels.append(entry.label)\n",
    "    \n",
    "    print 'Checked dictionary'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_bracket_dict(load_path):\n",
    "\n",
    "    library = rmgpy.data.kinetics.library.KineticsLibrary()\n",
    "    pattern = True\n",
    "    library.loadOldDictionary(load_path, pattern=pattern)\n",
    "    entries = library.entries.values()\n",
    "    \n",
    "   \n",
    "    bracket_path = os.path.join(load_path, '..', 'bracket_dictionary.txt')\n",
    "    f = open(bracket_path, 'w')\n",
    "    \n",
    "    for entry in entries:\n",
    "        f.write(entry.label)\n",
    "        f.write('\\n')\n",
    "        f.write(entry.item.toAdjacencyList())\n",
    "        f.write('\\n')\n",
    "                \n",
    "    f.close()\n",
    "    print 'Created \"bracket dictionary\" with multiplicities as lists'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rote_load_dict(path):\n",
    "    with open(path, 'r') as f:\n",
    "        entries_str = f.read().split('\\n\\n')\n",
    "\n",
    "    entries = {}\n",
    "    for entry_str in entries_str:\n",
    "        label, adjlist = entry_str.split('\\n', 1)\n",
    "        if re.search('(?<=multiplicity ).*', adjlist):\n",
    "            multiplicity = int(re.search('(?<=multiplicity ).*', adjlist).group(0))\n",
    "            adjlist = adjlist.split('\\n', 1)[1]\n",
    "            adjlist = 'multiplicity [{}]\\n'.format(multiplicity) + adjlist\n",
    "\n",
    "        group = rmgpy.molecule.group.Group()\n",
    "        group.fromAdjacencyList(adjlist)\n",
    "\n",
    "        entry = Entry()\n",
    "        entry.item = group\n",
    "        entry.label = label\n",
    "        entries[label] = entry\n",
    "    \n",
    "    print 'Old dictionary:', len(entries)\n",
    "    \n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ugly_save_dictionary(path, entries):\n",
    "    f = open(path, 'w')\n",
    "    for entry in entries:\n",
    "        multiplicity = entry.item.multiplicity\n",
    "        adjlist = entry.item.toAdjacencyList()\n",
    "        if multiplicity is not None:\n",
    "            #adjlist = re.sub(r'multiplicity .*', 'multiplicity {}'.format(multiplicity), adjlist)\n",
    "            adjlist = re.sub('\\[', '', adjlist)\n",
    "            adjlist = re.sub('\\]', '', adjlist)\n",
    "        f.write(entry.label)\n",
    "        f.write('\\n')\n",
    "        f.write(adjlist)\n",
    "        f.write('\\n')\n",
    "                \n",
    "    f.close()\n",
    "    print 'Saved new dictionary'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rote_save_dictionary(path, entries):\n",
    "    f = open(path, 'w')\n",
    "    for entry in entries.values():\n",
    "        multiplicity = entry.item.multiplicity\n",
    "        adjlist = entry.item.toAdjacencyList()\n",
    "        if multiplicity is not None:\n",
    "            adjlist = re.sub('\\[', '', adjlist)\n",
    "            adjlist = re.sub('\\]', '', adjlist)\n",
    "        f.write(entry.label)\n",
    "        f.write('\\n')\n",
    "        f.write(adjlist)\n",
    "        f.write('\\n')\n",
    "                \n",
    "    f.close()\n",
    "    print 'Saved new dictionary'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_reactions(path, csv_df, known_species, Method = '', ShortDesc = ''):\n",
    "    # Loading reactions database\n",
    "    from autotst.database import TransitionStateDepository, DistanceData\n",
    "    r_db = TransitionStateDepository()\n",
    "    local_context = {'DistanceData': DistanceData}\n",
    "    r_db.load(path, local_context=local_context)\n",
    "    \n",
    "    # Old r_db only has reactions already in reactions.py\n",
    "    old_r_db = TransitionStateDepository()\n",
    "    old_r_db.load(path, local_context=local_context)\n",
    "    \n",
    "    # New r_db will contain new reactions from the csv_df\n",
    "    new_r_db = TransitionStateDepository()\n",
    "\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    Index = 0\n",
    "    for entry in r_db.entries.values():\n",
    "        if Index < entry.index:\n",
    "            Index = entry.index\n",
    "    Index = Index + 1\n",
    "\n",
    "    for i, row in csv_df.T.iterrows():\n",
    "        #every reaction needs: distances, method, shortDesc, label, and reaction object\n",
    "\n",
    "        r1, r2, p1, p2 = row['species']\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        reaction = Reaction(reactants = [Species(molecule=[mr1]), Species(molecule=[mr2])],\n",
    "                            products = [Species(molecule=[mp1]), Species(molecule=[mp2])],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\n",
    "\n",
    "\n",
    "        Distances = {'d12':row['d12'], 'd13':row['d13'], 'd23':row['d23']}\n",
    "        distance_data = DistanceData(distances = Distances, method = Method)\n",
    "\n",
    "        relavent_species = [mr1, mr2, mp1, mp2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            \n",
    "            if rel_species not in found_species.keys():\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "\n",
    "        lr1 = relavent_labels[mr1]\n",
    "        lr2 = relavent_labels[mr2]\n",
    "        lp1 = relavent_labels[mp1]\n",
    "        lp2 = relavent_labels[mp2]\n",
    "\n",
    "        Label = '{} + {} <=> {} + {}'.format(lr1, lr2, lp1, lp2)\n",
    "        #print Label\n",
    "\n",
    "        # adding new entries to r_db, r_db will contain old and new reactions\n",
    "        r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = ShortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "        r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = reaction\n",
    "\n",
    "        # Adding new reactions to the new r_db as well\n",
    "        new_r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = ShortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "        new_r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = reaction\n",
    "\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    assert len(need_to_add) == 0, 'Species missing from dictionary'\n",
    "    assert len(r_db.entries) > len(old_r_db.entries) and len(r_db.entries) > len(new_r_db.entries)\n",
    "    assert len(r_db.entries) == len(old_r_db.entries) + len(new_r_db.entries) \n",
    "    \n",
    "    return r_db, old_r_db, new_r_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_known_reactions(path, reactions, known_species, method='', shortDesc=''):\n",
    "    # Loading reactions database\n",
    "    from autotst.database import TransitionStateDepository, DistanceData\n",
    "    r_db = TransitionStateDepository()\n",
    "    local_context = {'DistanceData': DistanceData}\n",
    "    r_db.load(path, local_context=local_context)\n",
    "    \n",
    "    # Old r_db only has reactions already in reactions.py\n",
    "    old_r_db = TransitionStateDepository()\n",
    "    old_r_db.load(path, local_context=local_context)\n",
    "    \n",
    "    # New r_db will contain new reactions from the csv_df\n",
    "    new_r_db = TransitionStateDepository()\n",
    "\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    Index = 0\n",
    "    for entry in r_db.entries.values():\n",
    "        if Index < entry.index:\n",
    "            Index = entry.index\n",
    "    Index = Index + 1\n",
    "    \n",
    "    for i, reaction in enumerate(reactions):\n",
    "        Distances = reaction.distance_data.distances\n",
    "        distance_data = DistanceData(distances = Distances, method = method)\n",
    "        \n",
    "        rmg_reaction = reaction.rmg_reaction\n",
    "        r1, r2 = rmg_reaction.reactants\n",
    "        p1, p2 = rmg_reaction.products\n",
    "        \n",
    "        relavent_species = [r1, r2, p1, p2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "            \n",
    "            if rel_species not in found_species.keys():\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "                logging.warning('{} not found in species dictionary'.format(rel_species))\n",
    "        \n",
    "        lr1 = found_species[r1]\n",
    "        lr2 = found_species[r2]\n",
    "        lp1 = found_species[p1]\n",
    "        lp2 = found_species[p2]\n",
    "\n",
    "        Label = '{} + {} <=> {} + {}'.format(lr1, lr2, lp1, lp2)\n",
    "        #print Label\n",
    "\n",
    "        # adding new entries to r_db, r_db will contain old and new reactions\n",
    "        r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = shortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "        r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = rmg_reaction\n",
    "\n",
    "        # Adding new reactions to the new r_db as well\n",
    "        new_r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = shortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "        new_r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = rmg_reaction\n",
    "\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    assert len(need_to_add) == 0, 'Species missing from dictionary'\n",
    "    assert len(r_db.entries) > len(old_r_db.entries) and len(r_db.entries) > len(new_r_db.entries)\n",
    "    assert len(r_db.entries) == len(old_r_db.entries) + len(new_r_db.entries) \n",
    "    \n",
    "    return r_db, old_r_db, new_r_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_databases_from_csv():\n",
    "    #csv_path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'AutoTST')\n",
    "\n",
    "    csv_path = 'distance_data.csv'\n",
    "    dict_path = 'database/H_Abstraction/TS_training/dictionary.txt'\n",
    "    old_style_dict_path = 'database/H_Abstraction/TS_training/old_dictionary.txt'\n",
    "    new_dict_path = 'updated_dictionary.txt'\n",
    "    method_str = 'm062x/6-311+G(2df,2p)'\n",
    "    shortDesc_str = 'M06-2X/6-311+G(2df,2p) calculation via group additive TS generator.'\n",
    "    old_reactions_path = 'database/H_Abstraction/TS_training/reactions.py'\n",
    "    new_reactions_path = 'updated_reactions.py'\n",
    "\n",
    "    csv_df = get_csv(csv_path)\n",
    "    print 'New Reactions: ',csv_df.shape[1]\n",
    "\n",
    "    known_species = rmgpy.data.base.Database().getSpecies(dict_path)\n",
    "    need_to_add = get_need_to_add(csv_df=csv_df, known_species=known_species)\n",
    "    print 'New Species: ', len(need_to_add)\n",
    "\n",
    "    all_dict_entries = get_updated_dictionary_entries(old_style_dict_path, need_to_add)\n",
    "    if check_dictionary(all_dict_entries):\n",
    "        ugly_save_dictionary(new_dict_path, all_dict_entries)\n",
    "\n",
    "    known_species = rmgpy.data.base.Database().getSpecies(new_dict_path)\n",
    "    r_db, old_db, new_db = update_reactions(old_reactions_path,\n",
    "                                            csv_df,\n",
    "                                            known_species,\n",
    "                                            Method = method_str,\n",
    "                                            ShortDesc = shortDesc_str\n",
    "                                           )\n",
    "    #TODO add check for duplicates method\n",
    "    #if check_reactions():\n",
    "    if True:\n",
    "        r_db.save(new_reactions_path)\n",
    "    print\n",
    "    print 'done?'\n",
    "    return new_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Reactions:  920\n",
      "New Species:  985\n",
      "Starting Species: 282\n",
      "Final Species: 1267\n",
      "Checked dictionary\n",
      "Saved new dictionary\n",
      "\n",
      "done?\n"
     ]
    }
   ],
   "source": [
    "new_db = update_databases_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_databases(reactions, method='', shortDesc='', reaction_family=''):\n",
    "    print 'Reactions to add:', len(reactions)\n",
    "    print\n",
    "    if reaction_family == '':\n",
    "        reaction_family = 'H_Abstraction'\n",
    "        logging.warning('Defaulting to reaction family of {}'.format(reaction_family))\n",
    "    \n",
    "    general_path = os.path.join(os.path.expandvars('$RMGpy'), '..', 'AutoTST', 'database', reaction_family, 'TS_training')\n",
    "    dict_path = os.path.join(general_path, 'dictionary.txt')\n",
    "    new_dict_path = os.path.join(general_path, 'updated_dictionary.txt')\n",
    "    old_reactions_path = os.path.join(general_path, 'reactions.py')\n",
    "    new_reactions_path = os.path.join(general_path, 'updated_reactions.py')\n",
    "\n",
    "    known_species = rmgpy.data.base.Database().getSpecies(dict_path)\n",
    "    print 'Known Species: ', len(known_species)\n",
    "    unknown_species = get_unknown_species(reactions, known_species)\n",
    "    print 'New Species: ', len(unknown_species)\n",
    "    print\n",
    "    \n",
    "    updated_known_species = []\n",
    "    if len(unknown_species) > 0:\n",
    "        old_dict_entries = rote_load_dict(dict_path)\n",
    "\n",
    "        assert len(known_species) == len(old_dict_entries)\n",
    "\n",
    "        all_dict_entries = update_dictionary_entries(old_dict_entries, unknown_species)\n",
    "        print 'New Dictionary:', len(all_dict_entries)\n",
    "        assert len(known_species) + len(unknown_species) == len(all_dict_entries)\n",
    "        #assert len(unknown_species) == len(all_dict_entries) - len(old_dict_entries)\n",
    "        \n",
    "        if check_dictionary_entries(all_dict_entries):\n",
    "            rote_save_dictionary(new_dict_path, all_dict_entries)\n",
    "    \n",
    "        updated_known_species = rmgpy.data.base.Database().getSpecies(new_dict_path)\n",
    "        unk_spec = get_unknown_species(reactions, updated_known_species)\n",
    "        assert len(unk_spec) == 0, '{} unknown species found after updating'.format(len(unk_spec))\n",
    "    else:\n",
    "        updated_known_species = known_species\n",
    "    \n",
    "    r_db, old_db, new_db = update_known_reactions(old_reactions_path,\n",
    "                                                  reactions,\n",
    "                                                  updated_known_species,\n",
    "                                                  method = method,\n",
    "                                                  shortDesc = shortDesc\n",
    "                                                 )\n",
    "    print\n",
    "    print 'Old Reactions:', len(old_db.entries)\n",
    "    print 'Reactions added:', len(new_db.entries)\n",
    "    print 'Final Reactions:', len(r_db.entries)\n",
    "    \n",
    "    #TODO add check for duplicates method\n",
    "    #if check_reactions_database():\n",
    "    if True:\n",
    "        logging.warning('No duplicate check for reactions database')\n",
    "        r_db.save(new_reactions_path)\n",
    "    print\n",
    "    print 'done?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-ffbbe7e44dc8>:6 update_databases WARNING Defaulting to reaction family of H_Abstraction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactions to add: 0\n",
      "\n",
      "Known Species:  282\n",
      "New Species:  0\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ef13c0101c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mupdate_databases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Method goes here'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortDesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'description goes here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-ffbbe7e44dc8>\u001b[0m in \u001b[0;36mupdate_databases\u001b[0;34m(reactions, method, shortDesc, reaction_family)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                   \u001b[0mupdated_known_species\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                                   \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                                                   \u001b[0mshortDesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshortDesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                                                  )\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-3b9783e12f88>\u001b[0m in \u001b[0;36mupdate_known_reactions\u001b[0;34m(path, reactions, known_species, method, shortDesc)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneed_to_add\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Species missing from dictionary'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_r_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_r_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_r_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_r_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "update_databases(test_reactions, method='Method goes here', shortDesc='description goes here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'C10H1O1-1'\n",
    "b, c = a.split('-')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rmg.py:72 __init__ WARNING Should only make one instance of RMGDatabase because it's stored as a module-level variable!\n",
      "rmg.py:73 __init__ WARNING Unexpected behaviour may result!\n",
      "thermo.py:839 loadLibraries INFO Loading thermodynamics library from primaryThermoLibrary.py in /home/C-Underkoffler/Code/RMG-Py/../RMG-database/input/thermo/libraries...\n",
      "thermo.py:839 loadLibraries INFO Loading thermodynamics library from thermo_DFT_CCSDTF12_BAC.py in /home/C-Underkoffler/Code/RMG-Py/../RMG-database/input/thermo/libraries...\n",
      "thermo.py:839 loadLibraries INFO Loading thermodynamics library from CBS_QB3_1dHR.py in /home/C-Underkoffler/Code/RMG-Py/../RMG-database/input/thermo/libraries...\n",
      "thermo.py:856 loadGroups INFO Loading thermodynamics group database from /home/C-Underkoffler/Code/RMG-Py/../RMG-database/input/thermo/groups...\n",
      "transport.py:294 loadGroups INFO Loading transport group database from /home/C-Underkoffler/Code/RMG-Py/../RMG-database/input/transport/groups...\n",
      "database.py:167 loadFamilies INFO Loading the user-specified kinetics families from /home/C-Underkoffler/Code/RMG-Py/../RMG-database/input/kinetics/families\n",
      "statmech.py:526 loadGroups INFO Loading frequencies group database from /home/C-Underkoffler/Code/RMG-Py/../RMG-database/input/statmech/groups...\n",
      "database.py:126 load INFO Loading transitions state family groups from /home/C-Underkoffler/Code/RMG-Py/../AutoTST/database/H_Abstraction/TS_groups.py\n",
      "reaction.py:138 __init__ INFO Label provided: C#CC+[O]O_C#C[CH2]+OO\n",
      "reaction.py:139 __init__ INFO Family provided: H_Abstraction\n",
      "reaction.py:248 get_rmg_reactions INFO The distance data is as follows: \n",
      "DistanceData(distances={'d12': 1.354216,'d13': 2.540456,'d23': 1.199295,}, uncertainties={'d12': 0.401416,'d13': 0.207102,'d23': 0.459032,}, comment=u'Matched node C/H3/Ct ([<Entry index=120 label=\"C/H3/Ct\">, <Entry index=222 label=\"Csj/Cs/O/H\">])\\nMatched node OjO ([<Entry index=126 label=\"C/H2/Cd/Cd\">, <Entry index=32 label=\"OjO\">])\\n')\n",
      "reaction.py:347 get_labels INFO The labled atoms are [4, 7, 0].\n",
      "reaction.py:292 create_rdkit_ts_geometry INFO Initially embedded molecule\n",
      "reaction.py:295 create_rdkit_ts_geometry INFO Editing bounds matrix\n",
      "reaction.py:362 set_limits INFO For atoms 4 and 7 we have a distance of: \t 1.354216\n",
      "reaction.py:362 set_limits INFO For atoms 7 and 0 we have a distance of: \t 1.199295\n",
      "reaction.py:362 set_limits INFO For atoms 4 and 0 we have a distance of: \t 2.540456\n",
      "reaction.py:417 bm_pre_edit INFO Changing lower limit 3.65 to 3.25991382266\n",
      "reaction.py:417 bm_pre_edit INFO Changing lower limit 2.530456 to 2.473511\n",
      "reaction.py:417 bm_pre_edit INFO Changing lower limit 2.62837475853 to 2.58837475853\n",
      "reaction.py:417 bm_pre_edit INFO Changing lower limit 2.22380768291 to 2.18380768291\n",
      "reaction.py:417 bm_pre_edit INFO Changing lower limit 2.9 to 2.435295\n",
      "reaction.py:299 create_rdkit_ts_geometry INFO Performing triangle smoothing on bounds matrix.\n",
      "reaction.py:304 create_rdkit_ts_geometry INFO Now attempting to embed using edited bounds matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mr1 = Molecule(SMILES = \"C#CC\")\\nmr2 = Molecule(SMILES = \"[O]O\")\\nmp1 = Molecule(SMILES = \"C#C[CH2]\")\\nmp2 = Molecule(SMILES = \"OO\")\\n\\nreaction = Reaction(reactants = [mr1, mr2],\\n                            products = [mp1, mp2],\\n                            degeneracy = 1,\\n                            duplicate = False,\\n                            reversible = True)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autotst.reaction import AutoTST_Reaction\n",
    "label = 'C#CC+[O]O_C#C[CH2]+OO'\n",
    "reaction = AutoTST_Reaction(label, reaction_family='H_Abstraction')\n",
    "\n",
    "test_reactions = []\n",
    "count = 0\n",
    "for entry in new_db.entries.values():\n",
    "    reaction = None\n",
    "    r1, r2 = entry.item.reactants\n",
    "    p1, p2 = entry.item.products\n",
    "    \n",
    "    r1 = r1.molecule[0].toSMILES()\n",
    "    r2 = r2.molecule[0].toSMILES()\n",
    "    p1 = p1.molecule[0].toSMILES()\n",
    "    p2 = p2.molecule[0].toSMILES()\n",
    "    \n",
    "    label = '{}+{}_{}+{}'.format(r1, r2, p1, p2)\n",
    "    #print label\n",
    "    if len(r2) > 12 and count < 10:\n",
    "        count += 1\n",
    "        #reaction = AutoTST_Reaction(label, reaction_family='H_Abstraction')\n",
    "        #print repr(reaction)\n",
    "        test_reactions.append(label)\n",
    "\n",
    "\"\"\"mr1 = Molecule(SMILES = \"C#CC\")\n",
    "mr2 = Molecule(SMILES = \"[O]O\")\n",
    "mp1 = Molecule(SMILES = \"C#C[CH2]\")\n",
    "mp2 = Molecule(SMILES = \"OO\")\n",
    "\n",
    "reaction = Reaction(reactants = [mr1, mr2],\n",
    "                            products = [mp1, mp2],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reaction.distance_data.distances\n",
    "#reaction.get_reactants_and_products()\n",
    "r1, r2 = reaction.reactant_mols\n",
    "r1 = r1.rmg_molecule\n",
    "r1\n",
    "test_reaction = reaction\n",
    "test_reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C+[CH2]COC(=O)C(C)C_CCOC(=O)C(C)C+[CH3]',\n",
       " 'O+[CH2]C(C)CC(C)C(C)=O_CC(=O)C(C)CC(C)C+[OH]',\n",
       " 'O+[CH2]C(C)OC(CC)CC_CCC(CC)OC(C)C+[OH]',\n",
       " 'O+[CH2]COC(=O)C(C)C_CCOC(=O)C(C)C+[OH]',\n",
       " 'O+[CH]=CC(C)=CCCC(=C)C_C=CC(C)=CCCC(=C)C+[OH]',\n",
       " 'OO+[CH2]C(=C)C(=O)CC_C=C(C)C(=O)CC+[O]O',\n",
       " 'OO+[CH2]C(=C)CC(C)=O_C=C(C)CC(C)=O+[O]O',\n",
       " 'OO+[CH2]C(=C)CCC=C(C)C=C_C=CC(C)=CCCC(=C)C+[O]O',\n",
       " 'OO+[CH2]C(=O)C(=C)C_C=C(C)C(C)=O+[O]O',\n",
       " 'OO+[CH2]C(=O)C(C)(C)C_CC(=O)C(C)(C)C+[O]O']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [ repr(reaction) for reaction in test_reactions]\n",
    "test_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Composite:', len(r_db.entries)\n",
    "print 'Old:', len(old_db.entries)\n",
    "print 'New', len(new_db.entries)\n",
    "\n",
    "#check_reactions(r_db, old_db, new_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checked_entries = []\n",
    "print 'Total:', len(old_db.entries)\n",
    "\n",
    "matches = 0\n",
    "exact_match = []\n",
    "mismatch = []\n",
    "mismatches = 0\n",
    "for entry in old_db.entries.values():\n",
    "    #print entry.item\n",
    "    for checked_entry in checked_entries:\n",
    "        if entry.item.isIsomorphic(checked_entry.item):\n",
    "            e_dists = set(entry.data.distances.values())\n",
    "            checked_e_dists = set(checked_entry.data.distances.values())\n",
    "            if e_dists == checked_e_dists:\n",
    "                exact_match.append(entry)\n",
    "                matches = matches + 1\n",
    "                \"\"\"print 'found exact match'\n",
    "                print entry.item\n",
    "                print entry.data\n",
    "                print entry.item.duplicate\n",
    "                print checked_entry.item\n",
    "                print checked_entry.data\n",
    "                print checked_entry.item.duplicate\n",
    "                assert False\"\"\"\n",
    "            elif e_dists != checked_e_dists:\n",
    "                mismatch.append(entry)\n",
    "                mismatches = mismatches + 1\n",
    "\n",
    "    checked_entries.append(entry)\n",
    "    \n",
    "print 'Matches: ', matches\n",
    "print 'Mismatches: ', mismatches \n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Total:', len(new_db.entries)\n",
    "checked_entries = {}\n",
    "matches = 0\n",
    "exact_match = []\n",
    "mismatch = []\n",
    "mismatches = 0\n",
    "for key in new_db.entries:\n",
    "    entry = new_db.entries[key]\n",
    "    for checked_key in checked_entries:\n",
    "        checked_entry = checked_entries[checked_key]\n",
    "        if entry.item.isIsomorphic(checked_entry.item, eitherDirection=False):\n",
    "            \n",
    "            e_dists = set(entry.data.distances.values())\n",
    "            checked_e_dists = set(checked_entry.data.distances.values())\n",
    "            \n",
    "            if e_dists == checked_e_dists:\n",
    "                exact_match.append(key)\n",
    "                matches = matches + 1\n",
    "                #del new_db.entries[key]\n",
    "            \n",
    "            elif e_dists != checked_e_dists:\n",
    "                mismatches = mismatches + 1  \n",
    "                print 'found mismatch'\n",
    "                print entry.item\n",
    "                print entry.data.distances\n",
    "                print entry.item.duplicate\n",
    "                print\n",
    "                print checked_entry.item\n",
    "                print checked_entry.data.distances\n",
    "                print checked_entry.item.duplicate\n",
    "                assert False\n",
    "                \"\"\"\"if Nate criteria:\n",
    "                    mismatches.append(key)\n",
    "                \"\"\"\n",
    "                \n",
    "            \n",
    "    checked_entries[key] = entry\n",
    "    \n",
    "print 'Matches: ', matches\n",
    "print 'Mismatches: ', mismatches \n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for duplicate in exact_match:\n",
    "    del new_db.entries[key]\n",
    "\n",
    "print len(new_db.entries.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_db.entries.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Species(molecule= [Molecule(SMILES = 'CCCC')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TODO Update Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = rmgpy.data.base.Database()\n",
    "x = this_is_mine(db)\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/old_dictionary.txt')\n",
    "pattern = True\n",
    "\n",
    "x.loadOldDictionary(path, pattern=pattern)\n",
    "\n",
    "x.database.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reactants = [Molecule(SMILES=\"CCCC\"), Molecule(SMILES=\"[O]O\")]\n",
    "products = [Molecule(SMILES=\"[CH2]CCC\"), Molecule(SMILES=\"OO\")]\n",
    "rmg_reaction = Reaction(reactants=reactants, products=products)\n",
    "rmg_reaction.degeneracy\n",
    "\n",
    "print rmg_reaction\n",
    "\n",
    "global_context = { '__builtins__': None }\n",
    "\n",
    "from autotst.database import DistanceData\n",
    "local_context = {\"entry\": Entry, 'DistanceData': DistanceData, \"nan\":np.nan}\n",
    "r_db = TransitionStateDepository()\n",
    "path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/reactions.py')\n",
    "r_db.load(path, local_context=local_context)\n",
    "#r_db.loadEntry\n",
    "#r_db.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'AutoTST', 'database')\n",
    "#path = os.path.join(path, 'H_Abstraction', 'TS_training', 'reactions.py')\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/reactions.py')\n",
    "\n",
    "r_df = get_existing_reactions(path)\n",
    "r_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_df.T.dropna(subset = ['label']).T\n",
    "r_df.drop_duplicates()\n",
    "r_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_db.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Found:', len(found_species)\n",
    "print 'Need to add:', len(need_to_add)\n",
    "print len(known_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for entry in r_db.entries.values():\n",
    "    if isinstance(entry.item, Reaction):\n",
    "        #Write out additional data if depository or library\n",
    "        #kinetic rules would have a Group object for its reactants instead of Species\n",
    "        try:\n",
    "            if isinstance(entry.item.reactants[0], Species):\n",
    "                # Add degeneracy if the reaction is coming from a depository or kinetics library\n",
    "                #print '    degeneracy = {0:.1f},\\n'.format(entry.item.degeneracy)\n",
    "                x = 1\n",
    "        except:\n",
    "            print entry\n",
    "            print entry.index\n",
    "            print entry.item\n",
    "            print entry.item.reactants\n",
    "            break\n",
    "\n",
    "r_db.save('test_saving')\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "found_species = {}\n",
    "need_to_add = []\n",
    "for specieseseses in csv_df.T['label']:\n",
    "    for species in specieseseses:\n",
    "        mole = Molecule(SMILES = species)\n",
    "        \n",
    "        for label in known_species:\n",
    "            known_spec = known_species[label]\n",
    "            if known_spec.isIsomorphic(mole):\n",
    "                found_species[mole] = label\n",
    "        \n",
    "        try:\n",
    "            a = found_species[mole]\n",
    "        except:\n",
    "            need_to_add.append(mole)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Found:', len(found_species)\n",
    "print 'Need to add:', len(need_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_DF(DF):\n",
    "    #print DF.shape\n",
    "\n",
    "    #print '\\t dropping NA Reactions'\n",
    "    DF = DF.T.dropna(subset = ['label']).T\n",
    "    \n",
    "    #print '\\t dropping NA Distances'\n",
    "    DF = DF.T.dropna(subset = ['d12']).T\n",
    "    DF = DF.T.dropna(subset = ['d13']).T\n",
    "    DF = DF.T.dropna(subset = ['d23']).T\n",
    "    #print DF.shape\n",
    "\n",
    "    #print '\\t dropping Column Duplicates'\n",
    "    DF = DF.T.drop_duplicates().T\n",
    "    #print DF.shape\n",
    "\n",
    "    \n",
    "    #print '\\t dropping Reaction Duplicates'\n",
    "    \n",
    "    #   sorting priorities: older > index\n",
    "    DF = DF.T.sort_values(['older reaction data', 'index']).T\n",
    "    DF = DF.T.drop_duplicates(['label'], keep = 'first').T\n",
    "    #print DF.shape\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print '\\tOld:'\n",
    "print r_df.count(axis = 1)\n",
    "print\n",
    "print '\\tAdditional:'\n",
    "print csv_df.count(axis = 1)\n",
    "\n",
    "DF = pd.concat([r_df, csv_df], axis = 1, ignore_index = True)\n",
    "print\n",
    "print '\\tBefore Trimming:'\n",
    "print DF.count(axis = 1)\n",
    "DF = trim_DF(DF)\n",
    "\n",
    "for index in DF.T.index:\n",
    "    DF[index]['index'] = index + 1\n",
    "\n",
    "print\n",
    "print '\\tAfter Trimming:'\n",
    "print DF.count(axis = 1)\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_existing_reactions(path):\n",
    "    global_context = { '__builtins__': None }\n",
    "\n",
    "    from autotst.database import DistanceData\n",
    "    local_context = {'DistanceData': DistanceData, \"nan\":np.nan}\n",
    "    r_db = TransitionStateDepository()\n",
    "    r_db.load(path, local_context=local_context)\n",
    "\n",
    "    results = defaultdict(OrderedDict)\n",
    "\n",
    "    for i, entry in enumerate(r_db.entries.values()):\n",
    "        r = OrderedDict()\n",
    "        r['index'] = entry.index\n",
    "        r['label'] = entry.label\n",
    "        r['degeneracy'] = entry.item.degeneracy\n",
    "        r['rank'] = entry.rank\n",
    "        r['method'] = entry.data.method\n",
    "        r['shortdesc'] = entry.shortDesc\n",
    "        r['older reaction data'] = 1\n",
    "\n",
    "        for key in entry.data.distances:\n",
    "            r[key] = entry.data.distances[key]\n",
    "\n",
    "        results[i] = r\n",
    "\n",
    "    reactions_df = pd.DataFrame(results)\n",
    "    return reactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(DF.shape[1]-1):\n",
    "        new_entry = rmgpy.data.base.Entry()\n",
    "        \n",
    "        new_entry.index = DF[index]['index']\n",
    "        new_entry.label = DF[index]['label']\n",
    "        #degeneracy = DF[index]['degeneracy']\n",
    "        reactants, products = DF[index]['label'].split(' <=> ')\n",
    "        print reactants\n",
    "        print products\n",
    "        r1, r2 = reactants.split(' + ')\n",
    "        p1, p2 = products.split(' + ')\n",
    "        #TODO Need to put reactanst and products into smiles\n",
    "        \"\"\"reactants = [Molecule(SMILES=r1), Molecule(SMILES=r2)]\n",
    "        products = [Molecule(SMILES=p1), Molecule(SMILES=p2)]\n",
    "        rmg_reaction = Reaction(reactants=reactants, products=products)\n",
    "        degeneracy = rmg_reaction.degeneracy\"\"\"\n",
    "        \n",
    "        d12 = DF[index]['d12']\n",
    "        d13 = DF[index]['d13']\n",
    "        d23 = DF[index]['d23']\n",
    "        \n",
    "        print new_entry.data\n",
    "        break\n",
    "        new_entry.data.method = DF[index]['method']\n",
    "        new_entry.data.distances = {'d12':d12, 'd13':d13, 'd23':d23}\n",
    "        \n",
    "        rank = DF[index]['rank']\n",
    "        shortDesc = DF[index]['shortDesc']\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ugly_write_new_reactions(path):\n",
    "    entries = []\n",
    "    for index in range(DF.shape[1]-1):\n",
    "        my_list = []\n",
    "        index = DF[index]['index']\n",
    "        label = DF[index]['label']\n",
    "        degeneracy = DF[index]['degeneracy']\n",
    "        d12 = DF[index]['d12']\n",
    "        d13 = DF[index]['d13']\n",
    "        d23 = DF[index]['d23']\n",
    "        method = DF[index]['method']\n",
    "        rank = DF[index]['rank']\n",
    "        shortDesc = DF[index]['shortDesc']\n",
    "\n",
    "        if rank != np.nan:\n",
    "            #Two options for when rank is not specified and when it is\n",
    "            #Ugly but wrote it as list to be a little easier to understand rather than large string with formatting\n",
    "            my_list = ['entry(\\n\\tindex = ',\n",
    "                       str(index),\n",
    "                       ',\\n\\tlabel = \\\"',\n",
    "                       label,\n",
    "                       '\\\",\\n\\tdegeneracy = ',\n",
    "                       str(degeneracy),\n",
    "                       ',\\n\\tdistances = DistanceData(\\n\\t\\tdistances = {\\'d12\\': ',\n",
    "                       str(d12),\n",
    "                       ', \\'d13\\': ',\n",
    "                       str(d13),\n",
    "                       ', \\'d23\\': ',\n",
    "                       str(d23),\n",
    "                       '},\\n\\t\\tmethod = \\'',\n",
    "                       method,\n",
    "                       '\\',\\n\\t),\\n\\trank = ',\n",
    "                       str(rank),\n",
    "                       ',\\n\\tshortDesc = u\\\"\\\"\\\"',\n",
    "                       shortDesc,\n",
    "                       '\\\"\\\"\\\",\\n)'\n",
    "                      ]\n",
    "        else:\n",
    "            my_list = ['entry(\\n\\tindex = ',\n",
    "                       str(index),\n",
    "                       ',\\n\\tlabel = \\\"',\n",
    "                       label,\n",
    "                       '\\\",\\n\\tdegeneracy = ',\n",
    "                       str(degeneracy),\n",
    "                       ',\\n\\tdistances = DistanceData(\\n\\t\\tdistances = {\\'d12\\': ',\n",
    "                       str(d12),\n",
    "                       ', \\'d13\\': ',\n",
    "                       str(d13),\n",
    "                       ', \\'d23\\': ',\n",
    "                       str(d23),\n",
    "                       '},\\n\\t\\tmethod = \\'',\n",
    "                       method,\n",
    "                       '\\',\\n\\t),\\n\\tshortDesc = u\\\"\\\"\\\"',\n",
    "                       shortDesc,\n",
    "                       '\\\"\\\"\\\",\\n)'\n",
    "                      ]\n",
    "\n",
    "        entries.append(''.join(my_list))\n",
    "\n",
    "    f = open(path, 'w')\n",
    "    f.write('\\n\\n'.join(entries))\n",
    "    f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'updated_reactions.py'\n",
    "ugly_write_new_reactions(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Update\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_context = { '__builtins__': None }\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/reactions.py')\n",
    "path = os.path.join(os.getcwd(), 'updater_test/reactions.py')\n",
    "from autotst.database import DistanceData\n",
    "local_context = {'DistanceData': DistanceData, \"nan\":np.nan}\n",
    "r_db = TransitionStateDepository()\n",
    "r_db.load(path, local_context=local_context)\n",
    "r_db.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blem = rmgpy.data.base.Database()\n",
    "blem.entries = blem.getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n",
    "blem.entries.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_species = rmgpy.data.base.Database().getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n",
    "known_species\n",
    "\n",
    "#print known_species.values()\n",
    "m1 = Molecule(SMILES=\"[CH2]C(C)CO\")\n",
    "relavent_labels = {}\n",
    "for label in known_species:\n",
    "    species = known_species[label]\n",
    "    if species.isIsomorphic(m1):\n",
    "        relavent_labels[m1] = label\n",
    "        break\n",
    "relavent_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "known_species = rmgpy.data.base.Database().getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n",
    "p_count = 0\n",
    "s_count = 0\n",
    "\n",
    "to_add = []\n",
    "total_species = []\n",
    "\n",
    "for reaction in csv_df.T['label']:\n",
    "    #print reaction\n",
    "    r, p = reaction.split(' <=> ')\n",
    "    r1, r2 = r.split(' + ')\n",
    "    p1, p2 = p.split(' + ')\n",
    "    #print r1, r2, p1, p2\n",
    "    involved_species = [Molecule(SMILES=r1),\n",
    "                        Molecule(SMILES=r2),\n",
    "                        Molecule(SMILES=p1),\n",
    "                        Molecule(SMILES=p2)]\n",
    "    \n",
    "    for a in involved_species:\n",
    "        c = False\n",
    "        for b in total_species:\n",
    "            if b.isIsomorphic(a):\n",
    "                c = True\n",
    "        if not c:\n",
    "            to_add.append(a)\n",
    "    \n",
    "    for new_species in involved_species:\n",
    "        matches_one = False\n",
    "        for old_species in known_species.values():\n",
    "            if old_species.isIsomorphic(new_species):\n",
    "                matches_one = True\n",
    "        \n",
    "        if matches_one:\n",
    "            p_count += 1\n",
    "        else:\n",
    "            to_add[new_species] = new_species.toAdjacencyList()\n",
    "            s_count += 1\n",
    "            \n",
    "print p_count\n",
    "print s_count\n",
    "\n",
    "print\n",
    "print len(known_species)\n",
    "print len(to_add)\n",
    "print len(list(set(to_add.keys())))\n",
    "print\n",
    "to_add.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_sp = []\n",
    "\n",
    "for reaction in csv_df.T['label']:\n",
    "    #print reaction\n",
    "    r, p = reaction.split(' <=> ')\n",
    "    r1, r2 = r.split(' + ')\n",
    "    p1, p2 = p.split(' + ')\n",
    "    \n",
    "    sp_list = [r1, r2, p1, p2]\n",
    "    print reaction\n",
    "    for sp in sp_list:\n",
    "        total_sp.append(sp)\n",
    "        \n",
    "print len(total_sp)/4\n",
    "total_sp = list(set(total_sp))\n",
    "print len(total_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1, r2 = entry.split(\"_\")[0].split(\"+\")\n",
    "m1 = Molecule(SMILES=r1)\n",
    "m2 = Molecule(SMILES=r2)\n",
    "combined = Molecule.merge(m1,m2)\n",
    "combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = RMGDatabase()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blem = rmgpy.data.base.Database()\n",
    "blem.getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blem.entries = OrderedDict({Molecule(SMILES=\"CCC\"): e})\n",
    "blem.saveDictionary(\"test.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#e = rmgpy.data.base.Entry(label=\"CCC\", item=Molecule(SMILES=\"CCC\").toAdjacencyList())\n",
    "print Molecule(SMILES=\"CCC\").toAdjacencyList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmg_database = RMGDatabase()\n",
    "database_path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'RMG-database', 'input')\n",
    "rmg_database.load(database_path,\n",
    "                 kineticsFamilies=['H_Abstraction'],\n",
    "                 transportLibraries=[],\n",
    "                 reactionLibraries=[],\n",
    "                 seedMechanisms=[],\n",
    "                 thermoLibraries=['primaryThermoLibrary', 'thermo_DFT_CCSDTF12_BAC', 'CBS_QB3_1dHR' ],\n",
    "                 solvation=False,\n",
    "                 )\n",
    "\n",
    "# TODO: Edit this so it works with multiple databases\n",
    "\n",
    "ts_database = TransitionStates()\n",
    "path = os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\", \"AutoTST\", \"database\", \"H_Abstraction\")\n",
    "global_context = { '__builtins__': None }\n",
    "local_context={'DistanceData': DistanceData}\n",
    "family = rmg_database.kinetics.families[\"H_Abstraction\"]\n",
    "ts_database.family = family\n",
    "ts_database.load(path, local_context, global_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class this_is_mine:\n",
    "    def __init__(self, database):\n",
    "        self.database = database\n",
    "    \n",
    "    def loadOldDictionary(self, path, pattern):\n",
    "            \"\"\"\n",
    "            Parse an old-style RMG database dictionary located at `path`. An RMG\n",
    "            dictionary is a list of key-value pairs of a one-line string key and a\n",
    "            multi-line string value. Each record is separated by at least one empty\n",
    "            line. Returns a ``dict`` object with the values converted to\n",
    "            :class:`Molecule` or :class:`Group` objects depending on the\n",
    "            value of `pattern`.\n",
    "            \"\"\"\n",
    "\n",
    "            # The dictionary being loaded\n",
    "            self.database.entries = {}\n",
    "            # The current record\n",
    "            record = ''\n",
    "\n",
    "            fdict=None\n",
    "            # Process the dictionary file\n",
    "            try:\n",
    "                fdict = open(path, 'r')\n",
    "                for line in fdict:\n",
    "                    line = line.strip()\n",
    "                    # If at blank line, end of record has been found\n",
    "                    if len(line) == 0 and len(record) > 0:\n",
    "                        # Label is first line of record\n",
    "                        lines = record.splitlines()\n",
    "                        label = lines[0]\n",
    "                        # Add record to dictionary\n",
    "                        self.database.entries[label] = Entry(label=label, item=record)\n",
    "                        # Clear record in preparation for next iteration\n",
    "                        record = ''\n",
    "                    # Otherwise append line to record (if not empty and not a comment line)\n",
    "                    else:\n",
    "                        line = removeCommentFromLine(line).strip()\n",
    "                        if len(line) > 0:\n",
    "                            record += line + '\\n'\n",
    "                # process the last record! (after end of for loop)\n",
    "                # Label is first line of record\n",
    "                if record:\n",
    "                    label = record.splitlines()[0]\n",
    "                    # Add record to dictionary\n",
    "                    self.database.entries[label] = Entry(label=label, item=record)\n",
    "            except DatabaseError, e:\n",
    "                logging.exception(str(e))\n",
    "                raise\n",
    "            except IOError, e:\n",
    "                logging.exception('Database dictionary file \"' + e.filename + '\" not found.')\n",
    "                raise\n",
    "            finally:\n",
    "                if fdict: fdict.close()\n",
    "\n",
    "            # Convert the records in the dictionary to Molecule, Group, or\n",
    "            # logical objects\n",
    "            try:\n",
    "                for label in self.database.entries:\n",
    "                    record = self.database.entries[label].item\n",
    "                    lines = record.splitlines()\n",
    "                    # If record is a logical node, make it into one.\n",
    "                    if re.match(\"(?i)\\s*(NOT\\s)?\\s*(OR|AND|UNION)\\s*(\\{.*\\})\", lines[1]):\n",
    "                        self.database.entries[label].item = makeLogicNode(' '.join(lines[1:]) )\n",
    "                    # Otherwise convert adjacency list to molecule or pattern\n",
    "                    elif pattern:\n",
    "                        self.database.entries[label].item = Group().fromAdjacencyList(record)\n",
    "                    else:\n",
    "                        self.database.entries[label].item = Molecule().fromAdjacencyList(record,saturateH=True)\n",
    "            except InvalidAdjacencyListError, e:\n",
    "                logging.error('Error while loading old-style dictionary \"{0}\"'.format(path))\n",
    "                logging.error('Error occurred while parsing adjacency list \"{0}\"'.format(label))\n",
    "                raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
