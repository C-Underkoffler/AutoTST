{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pylab\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "matplotlib.rc('mathtext', fontset='stixsans', default='regular')\n",
    "import re\n",
    "import rmgpy\n",
    "from rmgpy.quantity import constants\n",
    "from rmgpy.kinetics import Arrhenius, ArrheniusEP, KineticsData\n",
    "from rmgpy.data.base import getAllCombinations\n",
    "from autotst.database import *\n",
    "from rmgpy.species import Species\n",
    "from rmgpy.data.rmg import RMGDatabase\n",
    "import logging\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import IPython\n",
    "from IPython.display import display, Markdown\n",
    "def mprint(s): display(Markdown(s))\n",
    "import cPickle as pickle\n",
    "# attempt at making the cells wider:\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "from collections import defaultdict, OrderedDict\n",
    "import re\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv(path):\n",
    "    add_df = pd.DataFrame.from_csv(path)\n",
    "\n",
    "    results = defaultdict(OrderedDict)\n",
    "    for i, entry in enumerate(add_df.index):\n",
    "        r = OrderedDict()\n",
    "\n",
    "        label = add_df.T[entry].name\n",
    "        reactants, products = label.split('_')\n",
    "        r1, r2 = reactants.split('+')\n",
    "        p1, p2 = products.split('+')\n",
    "\n",
    "        #label = label.replace('+', ' + ')\n",
    "        #label = label.replace('_', ' <=> ')\n",
    "\n",
    "        #r['label'] = label\n",
    "\n",
    "        r['species'] = [r1, r2, p1, p2]\n",
    "        #print r['species']\n",
    "        assert len(r['species']) == 4\n",
    "        r['d12'] = add_df.T[entry]['d12']\n",
    "        r['d13'] = add_df.T[entry]['d13']\n",
    "        r['d23'] = add_df.T[entry]['d23']\n",
    "        assert r['d12'] > 0\n",
    "        assert r['d13'] > 0\n",
    "        assert r['d23'] > 0\n",
    "\n",
    "        #r['method'] = 'm062x/6-311+G(2df,2p)'\n",
    "        #r['older reaction data'] = np.nan\n",
    "        #r['index'] = np.nan\n",
    "        #r['degeneracy'] = 1\n",
    "        #r['rank'] = np.nan\n",
    "        #r['shortDesc'] = 'M06-2X/6-311+G(2df,2p) calculation via group additive TS generator.'\n",
    "\n",
    "        results[i] = r\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_need_to_add(csv_df, known_species):\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    for i, row in csv_df.T.iterrows():\n",
    "\n",
    "        r1, r2, p1, p2 = row['species']\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        reaction = Reaction(reactants = [mr1, mr2],\n",
    "                            products = [mp1, mp2],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\n",
    "\n",
    "        relavent_species = [mr1, mr2, mp1, mp2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            try:\n",
    "                a = found_species[rel_species]\n",
    "            except:\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "                relavent_labels[rel_species] = '****'\n",
    "                #logging.warning('{} is missing from species dictionary'.format(rel_species))\n",
    "\n",
    "        \"\"\"lr1 = relavent_labels[mr1]\n",
    "        lr2 = relavent_labels[mr2]\n",
    "        lp1 = relavent_labels[mp1]\n",
    "        lp2 = relavent_labels[mp2]\n",
    "\n",
    "        Label = '{} + {} <=> {} + {}'.format(lr1, lr2, lp1, lp2)\n",
    "        assert Label is not None\n",
    "        assert Label is not ''\n",
    "        print Label\"\"\"\n",
    "\n",
    "    need_to_add = list(set(need_to_add))\n",
    "    \n",
    "    return need_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_dictionary_entries(load_path, need_to_add):\n",
    "    \n",
    "    library = rmgpy.data.kinetics.library.KineticsLibrary()\n",
    "    pattern = True\n",
    "    library.loadOldDictionary(load_path, pattern=pattern)\n",
    "\n",
    "    print 'Starting Species:', len(library.entries.values()) \n",
    "\n",
    "    for i, entry in enumerate(library.entries.values()):\n",
    "        entry.index = i\n",
    "        library.entries[entry.index] = entry\n",
    "        del library.entries[entry.label]\n",
    "\n",
    "\n",
    "    i = i+2\n",
    "\n",
    "    for j, species in enumerate(need_to_add):\n",
    "        mole = Molecule(SMILES = species)\n",
    "\n",
    "        adjlist = mole.toAdjacencyList()\n",
    "        multiplicity = None\n",
    "        multiplicity =  adjlist[adjlist.find(\"multiplicity \")+13:adjlist.find(\"multiplicity \")+14]\n",
    "        if multiplicity is not None:\n",
    "            adjlist = re.sub(r'multiplicity .*', 'multiplicity [{}]'.format(multiplicity), adjlist)\n",
    "\n",
    "        group = rmgpy.molecule.group.Group()\n",
    "        group.fromAdjacencyList(adjlist)\n",
    "\n",
    "        atom_counts = {}\n",
    "        rel_label = ''\n",
    "        for atom in ['C', 'H', 'O']:\n",
    "            atom_counts[atom] = species.count(atom)\n",
    "            if species.count(atom) > 0:\n",
    "                rel_label = rel_label + atom + str(species.count(atom))\n",
    "\n",
    "        new_ID = None\n",
    "        max_ID = -1\n",
    "        for entry in library.entries.values():\n",
    "            existing_label = entry.label\n",
    "\n",
    "            if rel_label not in existing_label:\n",
    "                continue\n",
    "\n",
    "            if rel_label == existing_label:\n",
    "                # Atleast one, but not necessarily more existing with same label\n",
    "                max_ID = 0\n",
    "\n",
    "            #print rel_label, ' : ', existing_label\n",
    "            if existing_label.find('-') > 0:\n",
    "                ID_str = existing_label[existing_label.find('-')+1:]\n",
    "                ID = int(ID_str)\n",
    "                existing_label = existing_label[:existing_label.find('-')]\n",
    "\n",
    "                if existing_label == rel_label and ID > max_ID:\n",
    "                    # Multiple exisitng labels\n",
    "                    max_ID = ID\n",
    "\n",
    "        if max_ID > -1:\n",
    "            #All with existing labels\n",
    "            new_ID = max_ID + 1\n",
    "            rel_label = rel_label + '-' + str(new_ID)\n",
    "\n",
    "        #print '\\t', rel_label, ':', max_ID\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        3 Scenerios:\n",
    "        No existing -> no need for ID number\n",
    "        Only one existing -> needs to have ID of 1\n",
    "        Multiple existing -> needs to have a unique ID\n",
    "        \"\"\"\n",
    "\n",
    "        library.loadEntry(i+j,\n",
    "                          rel_label,\n",
    "                          None,\n",
    "                          degeneracy=1,\n",
    "                          duplicate=False,\n",
    "                          reversible=True,\n",
    "                          reference=None,\n",
    "                          referenceType='',\n",
    "                          shortDesc='',\n",
    "                          longDesc='',\n",
    "                          has_pdep_route=False,\n",
    "                          )\n",
    "\n",
    "        library.entries[i+j].item = group\n",
    "\n",
    "        \"\"\"library.entries[label] = Entry(index = i+j,\n",
    "                                       label = rel_label,\n",
    "                                       item = group,\n",
    "                                       data = None,\n",
    "                                       reference = None,\n",
    "                                       referenceType = '',\n",
    "                                       shortDesc = '',\n",
    "                                       longDesc = ''.strip(),\n",
    "                                      )\"\"\"\n",
    "    entry_labels = [entry.label for entry in library.entries.values()]\n",
    "    assert len(entry_labels) == len(list(set(entry_labels))), 'Non-unique labels in dictionary'\n",
    "\n",
    "    print 'Final Species:', len(library.entries)\n",
    "    return library.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ugly_save_dictionary(path, entries):\n",
    "    f = open(path, 'w')\n",
    "    for entry in entries:\n",
    "        multiplicity = entry.item.multiplicity\n",
    "        adjlist = entry.item.toAdjacencyList()\n",
    "        if multiplicity is not None:\n",
    "            #adjlist = re.sub(r'multiplicity .*', 'multiplicity {}'.format(multiplicity), adjlist)\n",
    "            adjlist = re.sub('\\[', '', adjlist)\n",
    "            adjlist = re.sub('\\]', '', adjlist)\n",
    "        f.write(entry.label)\n",
    "        f.write('\\n')\n",
    "        f.write(adjlist)\n",
    "        f.write('\\n')\n",
    "                \n",
    "    f.close()\n",
    "    print 'Saved new dictionary'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-133-b145513cdca5>:1: SyntaxWarning: import * only allowed at module level\n",
      "  def update_reactions():\n"
     ]
    }
   ],
   "source": [
    "def update_reactions():\n",
    "    from rmgpy.data.base import *\n",
    "    from autotst.database import DistanceData\n",
    "    r_db = TransitionStateDepository()\n",
    "    path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/reactions.py')\n",
    "    local_context = {'DistanceData': DistanceData, \"nan\":np.nan, \"entry\": Entry}\n",
    "    r_db.load(path, local_context=local_context)\n",
    "    # Remove above\n",
    "    # Remove above\n",
    "    # Remove above\n",
    "    # Remove above\n",
    "    # Remove above\n",
    "    # Remove above\n",
    "    # Remove above\n",
    "    # Remove above\n",
    "    # Remove above\n",
    "    known_species = rmgpy.data.base.Database().getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n",
    "\n",
    "    found_species = {}\n",
    "    need_to_add = []\n",
    "\n",
    "    Index = 0\n",
    "    for entry in r_db.entries.values():\n",
    "        if Index < entry.index:\n",
    "            Index = entry.index\n",
    "    Index = Index + 1\n",
    "\n",
    "    print Index\n",
    "    print\n",
    "\n",
    "    for i, row in csv_df.T.iterrows():\n",
    "\n",
    "        r1, r2, p1, p2 = row['species']\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        reaction = Reaction(reactants = [mr1, mr2],\n",
    "                            products = [mp1, mp2],\n",
    "                            degeneracy = 1,\n",
    "                            duplicate = False,\n",
    "                            reversible = True)\n",
    "\n",
    "\n",
    "        Distances = {'d12':row['d12'], 'd13':row['d13'], 'd23':row['d23']}\n",
    "        Method = 'm062x/6-311+G(2df,2p)'\n",
    "        distance_data = DistanceData(distances = Distances, method = Method)\n",
    "\n",
    "        \"\"\"entry = Entry(index = Index + i,\n",
    "                      label = 'prob not', #TODO Need to add back in\n",
    "                      item = reaction,\n",
    "                      data = distance_data, #TODO Need to add back in\n",
    "                      reference = None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = '',\n",
    "                      longDesc = ''.strip(),\n",
    "                      rank = None,\n",
    "                     )\"\"\"\n",
    "\n",
    "        Label = 'Please fix me'\n",
    "        ShortDesc = 'M06-2X/6-311+G(2df,2p) calculation via group additive TS generator.'\n",
    "\n",
    "\n",
    "        mr1 = Molecule(SMILES = r1)\n",
    "        mr2 = Molecule(SMILES = r2)\n",
    "        mp1 = Molecule(SMILES = p1)\n",
    "        mp2 = Molecule(SMILES = p2)\n",
    "\n",
    "        relavent_species = [mr1, mr2, mp1, mp2]\n",
    "        relavent_labels = {}\n",
    "\n",
    "        for rel_species in relavent_species:\n",
    "            for label in known_species:\n",
    "                known_spec = known_species[label]\n",
    "                if known_spec.isIsomorphic(rel_species):\n",
    "                    found_species[rel_species] = label\n",
    "                    relavent_labels[rel_species] = label\n",
    "\n",
    "            try:\n",
    "                a = found_species[rel_species]\n",
    "            except:\n",
    "                need_to_add.append(rel_species.toSMILES())\n",
    "                relavent_labels[rel_species] = '****'\n",
    "                logging.warning('{} is missing from species dictionary'.format(rel_species))\n",
    "\n",
    "        lr1 = relavent_labels[mr1]\n",
    "        lr2 = relavent_labels[mr2]\n",
    "        lp1 = relavent_labels[mp1]\n",
    "        lp2 = relavent_labels[mp2]\n",
    "\n",
    "        Label = '{} + {} <=> {} + {}'.format(lr1, lr2, lp1, lp2)\n",
    "        print Label\n",
    "\n",
    "\n",
    "        r_db.loadEntry(Index + i,\n",
    "                      reactant1=None,\n",
    "                      reactant2=None,\n",
    "                      reactant3=None,\n",
    "                      product1=None,\n",
    "                      product2=None,\n",
    "                      product3=None,\n",
    "                      distances = distance_data,\n",
    "                      degeneracy=1,\n",
    "                      label = Label,\n",
    "                      duplicate=False,\n",
    "                      reversible=True,\n",
    "                      reference=None,\n",
    "                      referenceType = '',\n",
    "                      shortDesc = ShortDesc,\n",
    "                      longDesc = '',\n",
    "                      rank=None,\n",
    "                      )\n",
    "\n",
    "\n",
    "        r_db.entries['{0:d}:{1}'.format(Index + i, Label)].item = reaction\n",
    "\n",
    "        #print\n",
    "        #print 'here'\n",
    "        #print entry.index\n",
    "        #print entry.label\n",
    "        #print entry.item.degeneracy\n",
    "        #print entry.rank\n",
    "        #print entry.data.method\n",
    "        #print entry.shortDesc\n",
    "\n",
    "    need_to_add = list(set(need_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Reactions:  920\n",
      "New Species:  985\n",
      "Starting Species: 282\n",
      "Final Species: 1267\n",
      "Saved new dictionary\n"
     ]
    }
   ],
   "source": [
    "#csv_path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'AutoTST')\n",
    "\n",
    "csv_path = 'distance_data.csv'\n",
    "dict_path = 'database/H_Abstraction/TS_training/dictionary.txt'\n",
    "old_style_dict_path = 'database/H_Abstraction/TS_training/old_dictionary.txt'\n",
    "new_dict_path = 'updated_dictionary.txt'\n",
    "\n",
    "csv_df = get_csv(csv_path)\n",
    "print 'New Reactions: ',csv_df.shape[1]\n",
    "\n",
    "known_species = rmgpy.data.base.Database().getSpecies(dict_path)\n",
    "need_to_add = get_need_to_add(csv_df=csv_df, known_species=known_species)\n",
    "print 'New Species: ', len(need_to_add)\n",
    "\n",
    "all_dict_entries = get_updated_dictionary_entries(old_style_dict_path, need_to_add)\n",
    "ugly_save_dictionary(new_dict_path, all_dict_entries)\n",
    "\n",
    "known_species = rmgpy.data.base.Database().getSpecies(new_dict_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TODO Update Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = rmgpy.data.base.Database()\n",
    "x = this_is_mine(db)\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/old_dictionary.txt')\n",
    "pattern = True\n",
    "\n",
    "x.loadOldDictionary(path, pattern=pattern)\n",
    "\n",
    "x.database.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reactants = [Molecule(SMILES=\"CCCC\"), Molecule(SMILES=\"[O]O\")]\n",
    "products = [Molecule(SMILES=\"[CH2]CCC\"), Molecule(SMILES=\"OO\")]\n",
    "rmg_reaction = Reaction(reactants=reactants, products=products)\n",
    "rmg_reaction.degeneracy\n",
    "\n",
    "print rmg_reaction\n",
    "\n",
    "global_context = { '__builtins__': None }\n",
    "\n",
    "from autotst.database import DistanceData\n",
    "local_context = {\"entry\": Entry, 'DistanceData': DistanceData, \"nan\":np.nan}\n",
    "r_db = TransitionStateDepository()\n",
    "path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/reactions.py')\n",
    "r_db.load(path, local_context=local_context)\n",
    "#r_db.loadEntry\n",
    "#r_db.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'AutoTST', 'database')\n",
    "#path = os.path.join(path, 'H_Abstraction', 'TS_training', 'reactions.py')\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/reactions.py')\n",
    "\n",
    "r_df = get_existing_reactions(path)\n",
    "r_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_df.T.dropna(subset = ['label']).T\n",
    "r_df.drop_duplicates()\n",
    "r_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_db.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Found:', len(found_species)\n",
    "print 'Need to add:', len(need_to_add)\n",
    "print len(known_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for entry in r_db.entries.values():\n",
    "    if isinstance(entry.item, Reaction):\n",
    "        #Write out additional data if depository or library\n",
    "        #kinetic rules would have a Group object for its reactants instead of Species\n",
    "        try:\n",
    "            if isinstance(entry.item.reactants[0], Species):\n",
    "                # Add degeneracy if the reaction is coming from a depository or kinetics library\n",
    "                #print '    degeneracy = {0:.1f},\\n'.format(entry.item.degeneracy)\n",
    "                x = 1\n",
    "        except:\n",
    "            print entry\n",
    "            print entry.index\n",
    "            print entry.item\n",
    "            print entry.item.reactants\n",
    "            break\n",
    "\n",
    "r_db.save('test_saving')\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "found_species = {}\n",
    "need_to_add = []\n",
    "for specieseseses in csv_df.T['label']:\n",
    "    for species in specieseseses:\n",
    "        mole = Molecule(SMILES = species)\n",
    "        \n",
    "        for label in known_species:\n",
    "            known_spec = known_species[label]\n",
    "            if known_spec.isIsomorphic(mole):\n",
    "                found_species[mole] = label\n",
    "        \n",
    "        try:\n",
    "            a = found_species[mole]\n",
    "        except:\n",
    "            need_to_add.append(mole)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Found:', len(found_species)\n",
    "print 'Need to add:', len(need_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_DF(DF):\n",
    "    #print DF.shape\n",
    "\n",
    "    #print '\\t dropping NA Reactions'\n",
    "    DF = DF.T.dropna(subset = ['label']).T\n",
    "    \n",
    "    #print '\\t dropping NA Distances'\n",
    "    DF = DF.T.dropna(subset = ['d12']).T\n",
    "    DF = DF.T.dropna(subset = ['d13']).T\n",
    "    DF = DF.T.dropna(subset = ['d23']).T\n",
    "    #print DF.shape\n",
    "\n",
    "    #print '\\t dropping Column Duplicates'\n",
    "    DF = DF.T.drop_duplicates().T\n",
    "    #print DF.shape\n",
    "\n",
    "    \n",
    "    #print '\\t dropping Reaction Duplicates'\n",
    "    \n",
    "    #   sorting priorities: older > index\n",
    "    DF = DF.T.sort_values(['older reaction data', 'index']).T\n",
    "    DF = DF.T.drop_duplicates(['label'], keep = 'first').T\n",
    "    #print DF.shape\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print '\\tOld:'\n",
    "print r_df.count(axis = 1)\n",
    "print\n",
    "print '\\tAdditional:'\n",
    "print csv_df.count(axis = 1)\n",
    "\n",
    "DF = pd.concat([r_df, csv_df], axis = 1, ignore_index = True)\n",
    "print\n",
    "print '\\tBefore Trimming:'\n",
    "print DF.count(axis = 1)\n",
    "DF = trim_DF(DF)\n",
    "\n",
    "for index in DF.T.index:\n",
    "    DF[index]['index'] = index + 1\n",
    "\n",
    "print\n",
    "print '\\tAfter Trimming:'\n",
    "print DF.count(axis = 1)\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_existing_reactions(path):\n",
    "    global_context = { '__builtins__': None }\n",
    "\n",
    "    from autotst.database import DistanceData\n",
    "    local_context = {'DistanceData': DistanceData, \"nan\":np.nan}\n",
    "    r_db = TransitionStateDepository()\n",
    "    r_db.load(path, local_context=local_context)\n",
    "\n",
    "    results = defaultdict(OrderedDict)\n",
    "\n",
    "    for i, entry in enumerate(r_db.entries.values()):\n",
    "        r = OrderedDict()\n",
    "        r['index'] = entry.index\n",
    "        r['label'] = entry.label\n",
    "        r['degeneracy'] = entry.item.degeneracy\n",
    "        r['rank'] = entry.rank\n",
    "        r['method'] = entry.data.method\n",
    "        r['shortdesc'] = entry.shortDesc\n",
    "        r['older reaction data'] = 1\n",
    "\n",
    "        for key in entry.data.distances:\n",
    "            r[key] = entry.data.distances[key]\n",
    "\n",
    "        results[i] = r\n",
    "\n",
    "    reactions_df = pd.DataFrame(results)\n",
    "    return reactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(DF.shape[1]-1):\n",
    "        new_entry = rmgpy.data.base.Entry()\n",
    "        \n",
    "        new_entry.index = DF[index]['index']\n",
    "        new_entry.label = DF[index]['label']\n",
    "        #degeneracy = DF[index]['degeneracy']\n",
    "        reactants, products = DF[index]['label'].split(' <=> ')\n",
    "        print reactants\n",
    "        print products\n",
    "        r1, r2 = reactants.split(' + ')\n",
    "        p1, p2 = products.split(' + ')\n",
    "        #TODO Need to put reactanst and products into smiles\n",
    "        \"\"\"reactants = [Molecule(SMILES=r1), Molecule(SMILES=r2)]\n",
    "        products = [Molecule(SMILES=p1), Molecule(SMILES=p2)]\n",
    "        rmg_reaction = Reaction(reactants=reactants, products=products)\n",
    "        degeneracy = rmg_reaction.degeneracy\"\"\"\n",
    "        \n",
    "        d12 = DF[index]['d12']\n",
    "        d13 = DF[index]['d13']\n",
    "        d23 = DF[index]['d23']\n",
    "        \n",
    "        print new_entry.data\n",
    "        break\n",
    "        new_entry.data.method = DF[index]['method']\n",
    "        new_entry.data.distances = {'d12':d12, 'd13':d13, 'd23':d23}\n",
    "        \n",
    "        rank = DF[index]['rank']\n",
    "        shortDesc = DF[index]['shortDesc']\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ugly_write_new_reactions(path):\n",
    "    entries = []\n",
    "    for index in range(DF.shape[1]-1):\n",
    "        my_list = []\n",
    "        index = DF[index]['index']\n",
    "        label = DF[index]['label']\n",
    "        degeneracy = DF[index]['degeneracy']\n",
    "        d12 = DF[index]['d12']\n",
    "        d13 = DF[index]['d13']\n",
    "        d23 = DF[index]['d23']\n",
    "        method = DF[index]['method']\n",
    "        rank = DF[index]['rank']\n",
    "        shortDesc = DF[index]['shortDesc']\n",
    "\n",
    "        if rank != np.nan:\n",
    "            #Two options for when rank is not specified and when it is\n",
    "            #Ugly but wrote it as list to be a little easier to understand rather than large string with formatting\n",
    "            my_list = ['entry(\\n\\tindex = ',\n",
    "                       str(index),\n",
    "                       ',\\n\\tlabel = \\\"',\n",
    "                       label,\n",
    "                       '\\\",\\n\\tdegeneracy = ',\n",
    "                       str(degeneracy),\n",
    "                       ',\\n\\tdistances = DistanceData(\\n\\t\\tdistances = {\\'d12\\': ',\n",
    "                       str(d12),\n",
    "                       ', \\'d13\\': ',\n",
    "                       str(d13),\n",
    "                       ', \\'d23\\': ',\n",
    "                       str(d23),\n",
    "                       '},\\n\\t\\tmethod = \\'',\n",
    "                       method,\n",
    "                       '\\',\\n\\t),\\n\\trank = ',\n",
    "                       str(rank),\n",
    "                       ',\\n\\tshortDesc = u\\\"\\\"\\\"',\n",
    "                       shortDesc,\n",
    "                       '\\\"\\\"\\\",\\n)'\n",
    "                      ]\n",
    "        else:\n",
    "            my_list = ['entry(\\n\\tindex = ',\n",
    "                       str(index),\n",
    "                       ',\\n\\tlabel = \\\"',\n",
    "                       label,\n",
    "                       '\\\",\\n\\tdegeneracy = ',\n",
    "                       str(degeneracy),\n",
    "                       ',\\n\\tdistances = DistanceData(\\n\\t\\tdistances = {\\'d12\\': ',\n",
    "                       str(d12),\n",
    "                       ', \\'d13\\': ',\n",
    "                       str(d13),\n",
    "                       ', \\'d23\\': ',\n",
    "                       str(d23),\n",
    "                       '},\\n\\t\\tmethod = \\'',\n",
    "                       method,\n",
    "                       '\\',\\n\\t),\\n\\tshortDesc = u\\\"\\\"\\\"',\n",
    "                       shortDesc,\n",
    "                       '\\\"\\\"\\\",\\n)'\n",
    "                      ]\n",
    "\n",
    "        entries.append(''.join(my_list))\n",
    "\n",
    "    f = open(path, 'w')\n",
    "    f.write('\\n\\n'.join(entries))\n",
    "    f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'updated_reactions.py'\n",
    "ugly_write_new_reactions(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Update\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_context = { '__builtins__': None }\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'database/H_Abstraction/TS_training/reactions.py')\n",
    "path = os.path.join(os.getcwd(), 'updater_test/reactions.py')\n",
    "from autotst.database import DistanceData\n",
    "local_context = {'DistanceData': DistanceData, \"nan\":np.nan}\n",
    "r_db = TransitionStateDepository()\n",
    "r_db.load(path, local_context=local_context)\n",
    "r_db.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blem = rmgpy.data.base.Database()\n",
    "blem.entries = blem.getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n",
    "blem.entries.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_species = rmgpy.data.base.Database().getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n",
    "known_species\n",
    "\n",
    "#print known_species.values()\n",
    "m1 = Molecule(SMILES=\"[CH2]C(C)CO\")\n",
    "relavent_labels = {}\n",
    "for label in known_species:\n",
    "    species = known_species[label]\n",
    "    if species.isIsomorphic(m1):\n",
    "        relavent_labels[m1] = label\n",
    "        break\n",
    "relavent_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "known_species = rmgpy.data.base.Database().getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n",
    "p_count = 0\n",
    "s_count = 0\n",
    "\n",
    "to_add = []\n",
    "total_species = []\n",
    "\n",
    "for reaction in csv_df.T['label']:\n",
    "    #print reaction\n",
    "    r, p = reaction.split(' <=> ')\n",
    "    r1, r2 = r.split(' + ')\n",
    "    p1, p2 = p.split(' + ')\n",
    "    #print r1, r2, p1, p2\n",
    "    involved_species = [Molecule(SMILES=r1),\n",
    "                        Molecule(SMILES=r2),\n",
    "                        Molecule(SMILES=p1),\n",
    "                        Molecule(SMILES=p2)]\n",
    "    \n",
    "    for a in involved_species:\n",
    "        c = False\n",
    "        for b in total_species:\n",
    "            if b.isIsomorphic(a):\n",
    "                c = True\n",
    "        if not c:\n",
    "            to_add.append(a)\n",
    "    \n",
    "    for new_species in involved_species:\n",
    "        matches_one = False\n",
    "        for old_species in known_species.values():\n",
    "            if old_species.isIsomorphic(new_species):\n",
    "                matches_one = True\n",
    "        \n",
    "        if matches_one:\n",
    "            p_count += 1\n",
    "        else:\n",
    "            to_add[new_species] = new_species.toAdjacencyList()\n",
    "            s_count += 1\n",
    "            \n",
    "print p_count\n",
    "print s_count\n",
    "\n",
    "print\n",
    "print len(known_species)\n",
    "print len(to_add)\n",
    "print len(list(set(to_add.keys())))\n",
    "print\n",
    "to_add.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_sp = []\n",
    "\n",
    "for reaction in csv_df.T['label']:\n",
    "    #print reaction\n",
    "    r, p = reaction.split(' <=> ')\n",
    "    r1, r2 = r.split(' + ')\n",
    "    p1, p2 = p.split(' + ')\n",
    "    \n",
    "    sp_list = [r1, r2, p1, p2]\n",
    "    print reaction\n",
    "    for sp in sp_list:\n",
    "        total_sp.append(sp)\n",
    "        \n",
    "print len(total_sp)/4\n",
    "total_sp = list(set(total_sp))\n",
    "print len(total_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1, r2 = entry.split(\"_\")[0].split(\"+\")\n",
    "m1 = Molecule(SMILES=r1)\n",
    "m2 = Molecule(SMILES=r2)\n",
    "combined = Molecule.merge(m1,m2)\n",
    "combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = RMGDatabase()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blem = rmgpy.data.base.Database()\n",
    "blem.getSpecies(\"./database/H_Abstraction/TS_training/dictionary.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blem.entries = OrderedDict({Molecule(SMILES=\"CCC\"): e})\n",
    "blem.saveDictionary(\"test.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#e = rmgpy.data.base.Entry(label=\"CCC\", item=Molecule(SMILES=\"CCC\").toAdjacencyList())\n",
    "print Molecule(SMILES=\"CCC\").toAdjacencyList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmg_database = RMGDatabase()\n",
    "database_path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'RMG-database', 'input')\n",
    "rmg_database.load(database_path,\n",
    "                 kineticsFamilies=['H_Abstraction'],\n",
    "                 transportLibraries=[],\n",
    "                 reactionLibraries=[],\n",
    "                 seedMechanisms=[],\n",
    "                 thermoLibraries=['primaryThermoLibrary', 'thermo_DFT_CCSDTF12_BAC', 'CBS_QB3_1dHR' ],\n",
    "                 solvation=False,\n",
    "                 )\n",
    "\n",
    "# TODO: Edit this so it works with multiple databases\n",
    "\n",
    "ts_database = TransitionStates()\n",
    "path = os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\", \"AutoTST\", \"database\", \"H_Abstraction\")\n",
    "global_context = { '__builtins__': None }\n",
    "local_context={'DistanceData': DistanceData}\n",
    "family = rmg_database.kinetics.families[\"H_Abstraction\"]\n",
    "ts_database.family = family\n",
    "ts_database.load(path, local_context, global_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class this_is_mine:\n",
    "    def __init__(self, database):\n",
    "        self.database = database\n",
    "    \n",
    "    def loadOldDictionary(self, path, pattern):\n",
    "            \"\"\"\n",
    "            Parse an old-style RMG database dictionary located at `path`. An RMG\n",
    "            dictionary is a list of key-value pairs of a one-line string key and a\n",
    "            multi-line string value. Each record is separated by at least one empty\n",
    "            line. Returns a ``dict`` object with the values converted to\n",
    "            :class:`Molecule` or :class:`Group` objects depending on the\n",
    "            value of `pattern`.\n",
    "            \"\"\"\n",
    "\n",
    "            # The dictionary being loaded\n",
    "            self.database.entries = {}\n",
    "            # The current record\n",
    "            record = ''\n",
    "\n",
    "            fdict=None\n",
    "            # Process the dictionary file\n",
    "            try:\n",
    "                fdict = open(path, 'r')\n",
    "                for line in fdict:\n",
    "                    line = line.strip()\n",
    "                    # If at blank line, end of record has been found\n",
    "                    if len(line) == 0 and len(record) > 0:\n",
    "                        # Label is first line of record\n",
    "                        lines = record.splitlines()\n",
    "                        label = lines[0]\n",
    "                        # Add record to dictionary\n",
    "                        self.database.entries[label] = Entry(label=label, item=record)\n",
    "                        # Clear record in preparation for next iteration\n",
    "                        record = ''\n",
    "                    # Otherwise append line to record (if not empty and not a comment line)\n",
    "                    else:\n",
    "                        line = removeCommentFromLine(line).strip()\n",
    "                        if len(line) > 0:\n",
    "                            record += line + '\\n'\n",
    "                # process the last record! (after end of for loop)\n",
    "                # Label is first line of record\n",
    "                if record:\n",
    "                    label = record.splitlines()[0]\n",
    "                    # Add record to dictionary\n",
    "                    self.database.entries[label] = Entry(label=label, item=record)\n",
    "            except DatabaseError, e:\n",
    "                logging.exception(str(e))\n",
    "                raise\n",
    "            except IOError, e:\n",
    "                logging.exception('Database dictionary file \"' + e.filename + '\" not found.')\n",
    "                raise\n",
    "            finally:\n",
    "                if fdict: fdict.close()\n",
    "\n",
    "            # Convert the records in the dictionary to Molecule, Group, or\n",
    "            # logical objects\n",
    "            try:\n",
    "                for label in self.database.entries:\n",
    "                    record = self.database.entries[label].item\n",
    "                    lines = record.splitlines()\n",
    "                    # If record is a logical node, make it into one.\n",
    "                    if re.match(\"(?i)\\s*(NOT\\s)?\\s*(OR|AND|UNION)\\s*(\\{.*\\})\", lines[1]):\n",
    "                        self.database.entries[label].item = makeLogicNode(' '.join(lines[1:]) )\n",
    "                    # Otherwise convert adjacency list to molecule or pattern\n",
    "                    elif pattern:\n",
    "                        self.database.entries[label].item = Group().fromAdjacencyList(record)\n",
    "                    else:\n",
    "                        self.database.entries[label].item = Molecule().fromAdjacencyList(record,saturateH=True)\n",
    "            except InvalidAdjacencyListError, e:\n",
    "                logging.error('Error while loading old-style dictionary \"{0}\"'.format(path))\n",
    "                logging.error('Error occurred while parsing adjacency list \"{0}\"'.format(label))\n",
    "                raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
